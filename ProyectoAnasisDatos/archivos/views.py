# Standard Library
import os
import io
import uuid
import mimetypes
from io import BytesIO

# Data Processing
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Configuraci√≥n para evitar conflictos con GUI
import matplotlib.pyplot as plt
from PIL import Image  # Para procesamiento de im√°genes
import base64
import json
import plotly.graph_objs as go
import seaborn as sns

from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import LabelEncoder

# Django modeling
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
from sklearn.ensemble import RandomForestClassifier

# Django Core
from django.shortcuts import render, redirect, get_object_or_404
from django.conf import settings
from django.http import JsonResponse, FileResponse, HttpResponse, HttpResponseRedirect
from django.urls import reverse
from django.template.loader import render_to_string
from django.contrib import messages
from django.contrib.auth import authenticate, login as auth_login
from django.views.decorators.cache import never_cache
from django.contrib.auth.decorators import login_required, user_passes_test
from django.contrib.auth.models import User
from django.contrib.auth.forms import UserCreationForm
from django.views.decorators.csrf import csrf_protect
from django.views.decorators.http import require_POST
from django.db import IntegrityError
from django import forms
from django.contrib.auth.forms import UserCreationForm
from django.contrib.auth.models import User
from django.views.decorators.http import require_POST

# App Specific
from .models import ArchivoSubido
from .forms import ArchivoForm
from django.contrib.auth.decorators import user_passes_test
from django.contrib.auth import logout


def superuser_check(user):
    return user.is_superuser

@user_passes_test(superuser_check)
def vista_exclusiva_superuser(request):
    # Vista solo para superusuarios
    return render(request, 'admin/superuser_panel.html')
""""
@csrf_protect
def login_views(request):
    error = None
    if request.method == 'POST':
        username = request.POST.get('username')
        password = request.POST.get('password')
        user = authenticate(request, username=username, password=password)
        if user is not None:
            auth_login(request, user)
            return redirect('interfaz')  # Redirige a tu p√°gina principal
        else:
            error = "Usuario o contrase√±a incorrectos"
    return render(request, 'login.html', {'error': error})
"""""
@csrf_protect

def login_view(request):
    if request.user.is_authenticated:
        return redirect('interfaz')
    
    if request.method == 'POST':
        username = request.POST.get('username')
        password = request.POST.get('password')
        user = authenticate(request, username=username, password=password)
        
        if user is not None:
            auth_login(request, user)
            next_url = request.POST.get('next', 'interfaz')  # Redirige a 'next' o dashboard
            return redirect(next_url)
        else:
            error = "Credenciales inv√°lidas"
            return render(request, 'login.html', {'error': error})
    
    return render(request, 'login.html')

@login_required
@never_cache

def interfaz(request):
    archivos = ArchivoSubido.objects.all()
    return render(request, 'interfaz.html', {'archivos': archivos})

class CustomUserCreationForm(UserCreationForm):
    email = forms.EmailField(required=True)

    class Meta:
        model = User
        fields = ("username", "email", "password1", "password2")

    def clean_username(self):
        username = self.cleaned_data['username']
        if User.objects.filter(username=username).exists():
            raise forms.ValidationError("Este nombre de usuario ya est√° en uso.")
        return username

    def save(self, commit=True):
        user = super().save(commit=False)
        user.email = self.cleaned_data["email"]
        if commit:
            user.save()
        return user

def landing_page(request):
    return render(request, 'landing.html')

@login_required
def subir_archivo(request):
    if request.method == 'POST':
        archivo = request.FILES.get("archivo")
        nombre = request.POST.get("nombre", "").strip()

        if archivo:
            # Si no se escribi√≥ un nombre, usar el nombre del archivo subido
            if not nombre:
                nombre = os.path.basename(archivo.name)

            nuevo_archivo = ArchivoSubido(nombre=nombre, archivo=archivo)
            nuevo_archivo.save()

            messages.success(request, f"Archivo '{nuevo_archivo.nombre}' subido exitosamente")

            if request.headers.get('x-requested-with') == 'XMLHttpRequest':
                return JsonResponse({'success': True, 'nombre': nuevo_archivo.nombre})

            return redirect('interfaz')  # Redirige al dashboard principal
        else:
            messages.error(request, "Debes seleccionar un archivo v√°lido.")

    return render(request, 'subir_archivo.html')



@login_required
def listar_archivos(request):
    archivos = ArchivoSubido.objects.all()

    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        return render(request, 'partials/listar_contenido.html', {'archivos': archivos})
    return render(request, 'listar_archivos.html', {'archivos': archivos})

@require_POST  # Asegura que solo se pueda llamar via POST
def custom_logout(request):
    logout(request)
    request.session.flush()
    response = redirect('landing')  # Redirige a tu p√°gina landing
    response.delete_cookie('sessionid')
    response.delete_cookie('csrftoken')
    return response

@login_required
def analizar_archivo(request, archivo_id):
    archivo_obj = get_object_or_404(ArchivoSubido, id=archivo_id)
    ruta_completa = os.path.join(settings.MEDIA_ROOT, archivo_obj.archivo.name)

    if ruta_completa.endswith('.csv'):
        df = pd.read_csv(ruta_completa)
    elif ruta_completa.endswith('.xlsx'):
        df = pd.read_excel(ruta_completa)
    else:
        df = pd.DataFrame({'Error': ['Formato no soportado']})

    tabla_html = df.to_html(classes='table table-striped')

    contexto = {'tabla': tabla_html, 'archivo': archivo_obj}
    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        return render(request, 'partials/analizar_contenido.html', contexto)
    return render(request, 'analizar_archivo.html', contexto)

@login_required
def ver_archivo(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    filepath = archivo.archivo.path
    extension = os.path.splitext(filepath)[1].lower()

    if extension in ['.csv', '.xlsx', '.xls']:
        try:
            df = pd.read_csv(filepath, delimiter=';', on_bad_lines='skip')

            if df.columns.isnull().any():
                df.columns = [f"Columna_{i+1}" for i in range(df.shape[1])]

            nulos = df.isnull().sum().sum()
            ceros = (df == 0).sum().sum()
            columnas = df.columns.tolist()

            # --- Preparar gr√°fico simple (puedes quitar si no usas) ---
            x_col = request.GET.get('x', columnas[0])
            y_col = request.GET.get('y', columnas[1] if len(columnas) > 1 else columnas[0])

            fig, ax = plt.subplots()
            df[y_col] = pd.to_numeric(df[y_col], errors='coerce')
            df_grafico = df[[x_col, y_col]].dropna()

            if not df_grafico.empty:
                df_grafico.plot(x=x_col, y=y_col, ax=ax)
            else:
                ax.text(0.5, 0.5, "No hay datos v√°lidos para graficar", 
                        ha='center', va='center', transform=ax.transAxes)

            filename = f"{uuid.uuid4()}.png"
            ruta_imagen = os.path.join(settings.MEDIA_ROOT, filename)
            fig.savefig(ruta_imagen, bbox_inches='tight')
            plt.close(fig)
            url_imagen = settings.MEDIA_URL + filename

            # --- An√°lisis descriptivo ---
            df_numerico = df.select_dtypes(include='number')
            descripcion = df_numerico.describe()

            if request.GET.get('ocultar') == '1':
                descripcion = descripcion.loc[:, descripcion.loc['count'] != 0.0]

            descripcion_html = descripcion.fillna('').to_html(
                classes="table table-striped table-bordered"
            )

            # --- Tabla completa o preview ---
            with pd.option_context('display.max_rows', None, 'display.max_columns', None):
                if request.GET.get('completo') == '1':
                    tabla_html = df.to_html(classes="table table-striped table-bordered")
                else:
                    tabla_html = df.head(7).to_html(classes="table table-striped table-bordered")

            contexto = {
                'df': tabla_html,
                'descripcion': descripcion_html,
                'archivo': archivo,
                'grafico_url': url_imagen,
                'nulos': nulos,
                'ceros': ceros,
                'columnas': columnas
            }

            # --- AJAX: solo devolver partials ---
            if request.headers.get('x-requested-with') == 'XMLHttpRequest':
                if request.GET.get('completo') == '1':
                    # Solo tabla completa
                    return render(request, 'partials/tabla_completa.html', {'df': tabla_html})
                else:
                    # Vista previa y an√°lisis
                    return render(request, 'partials/ver_contenido.html', contexto)

            # --- Render normal ---
            return render(request, 'ver_archivo.html', contexto)

        except Exception as e:
            return render(request, 'ver_grafica.html', {
                'archivo': archivo,
                'columnas': [],
                'error': str(e)
            })



@login_required
def ver_grafica(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    df = pd.read_csv(archivo.archivo.path, sep=';', on_bad_lines='skip')
    columnas = df.columns.tolist()

    x = request.GET.get('x')
    y = request.GET.get('y')
    tipo = request.GET.get('tipo', 'line')

    grafico_url = None
    error = None

    try:
        fig, ax = plt.subplots(figsize=(10, 6))

        # üîπ Histograma o Boxplot ‚Äî solo requieren una columna
        if tipo in ['hist', 'box'] and y and y in df.columns:
            df[y] = pd.to_numeric(df[y], errors='coerce')
            df = df[[y]].dropna()

            if tipo == 'hist':
                df[y].plot.hist(ax=ax, bins=30, color='skyblue')
                ax.set_title(f"Histograma de {y}")
                ax.set_xlabel(y)
                ax.set_ylabel("Frecuencia")

            elif tipo == 'box':
                df[[y]].plot.box(ax=ax)
                ax.set_title(f"Boxplot de {y}")

        # üîπ Gr√°ficos con X e Y
        elif x and y and x in df.columns and y in df.columns:
            df = df[[x, y]].dropna()
            df[y] = pd.to_numeric(df[y], errors='coerce')

            if tipo == 'line':
                df_sorted = df.sort_values(by=x)
                ax.plot(df_sorted[x], df_sorted[y], marker='o')
                ax.set_title(f"Tendencia: {y} vs {x}")
                ax.set_xlabel(x)
                ax.set_ylabel(y)

            elif tipo == 'bar':
                if df[x].nunique() < 30:
                    df_grouped = df.groupby(x)[y].mean().reset_index()
                    ax.bar(df_grouped[x], df_grouped[y])
                    ax.set_title(f"Barras: promedio de {y} por {x}")
                    ax.set_xlabel(x)
                    ax.set_ylabel(f"{y} (promedio)")
                else:
                    raise ValueError("Demasiados valores √∫nicos en X para gr√°fico de barras.")

            elif tipo == 'pie':
                if df[y].nunique() < 20:
                    conteo = df[y].value_counts().head(10)
                    conteo.plot.pie(ax=ax, autopct='%1.1f%%', startangle=90)
                    ax.set_ylabel('')
                    ax.set_title(f"Torta de {y}")
                else:
                    raise ValueError("Gr√°fico de torta solo disponible para columnas con pocos valores √∫nicos.")
            else:
                raise ValueError("Tipo de gr√°fico no v√°lido.")

        else:
            raise ValueError("Selecciona correctamente las columnas X e Y o solo Y seg√∫n el tipo de gr√°fico.")

        buf = BytesIO()
        plt.tight_layout()
        plt.savefig(buf, format='png')
        plt.close(fig)
        grafico_url = 'data:image/png;base64,' + base64.b64encode(buf.getvalue()).decode()
        buf.close()

    except Exception as e:
        error = str(e)

    context = {
        'archivo': archivo,
        'columnas': columnas,
        'grafico_url': grafico_url,
        'error': error,
        'x_seleccionada': x,
        'y_seleccionada': y,
        'tipo': tipo,
    }

    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        html = render_to_string('partials/fragmento_grafica.html', context)
        return JsonResponse({'html': html})

    return render(request, 'ver_grafica.html', context)



@login_required
def analisis_grafico(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    filepath = archivo.archivo.path
    extension = os.path.splitext(filepath)[1].lower()

    if extension in ['.csv', '.xlsx', '.xls']:
        try:
            df = pd.read_csv(filepath, delimiter=';', on_bad_lines='skip')

            # Eliminar fila final si es completamente NaN
            if df.tail(1).isnull().all(axis=1).any():
                df = df.iloc[:-1]

            # ‚úÖ Filtrar columnas eliminando las que son texto puro (object)
            columnas_texto = df.select_dtypes(include=['object', 'string']).columns.tolist()
            columnas_permitidas = [col for col in df.columns if col not in columnas_texto]

            if request.headers.get('x-requested-with') == 'XMLHttpRequest':
                columnas_seleccionadas = request.GET.getlist('columnas')
                tipo = request.GET.get('tipo')

                graficos = []

                for col in columnas_seleccionadas:
                    if col not in df.columns:
                        continue
                    
                    fig, ax = plt.subplots()
                    df[col] = pd.to_numeric(df[col], errors='coerce')

                    if tipo == 'hist':
                        df[col].dropna().plot.hist(ax=ax, bins=30, color='skyblue')
                        ax.set_title(f"Histograma de {col}")
                    elif tipo == 'box':
                        df[[col]].dropna().plot.box(ax=ax)
                        ax.set_title(f"Boxplot de {col}")
                    elif tipo == 'pie':
                        conteo = df[col].value_counts().head(10)
                        ax.pie(conteo, labels=conteo.index, autopct='%1.1f%%')
                        ax.set_title(f"Gr√°fico de torta de {col}")
                        ax.set_ylabel("")
                    elif tipo == 'bar':
                        conteo = df[col].value_counts().head(15)
                        ax.bar(conteo.index, conteo.values)
                        ax.set_title(f"Gr√°fico de barras de {col}")
                        ax.set_xticklabels(conteo.index, rotation=45, ha='right')
                    elif tipo == 'line':
                        df[col].dropna().reset_index(drop=True).plot(ax=ax)
                        ax.set_title(f"Gr√°fico de l√≠nea de {col}")
                        ax.set_xlabel("√çndice")
                        ax.set_ylabel(col)
                    else:
                        continue

                    buf = BytesIO()
                    plt.tight_layout()
                    plt.savefig(buf, format='png')
                    plt.close(fig)
                    imagen_base64 = base64.b64encode(buf.getvalue()).decode()
                    buf.close()

                    graficos.append({
                        'columna': col,
                        'imagen': f'data:image/png;base64,{imagen_base64}'
                    })

                html = render_to_string('partials/fragmento_analisis_grafica.html', {'graficos': graficos})
                return JsonResponse({'html': html})

            # Si no es AJAX, carga solo la p√°gina base con el formulario (solo columnas permitidas)
            contexto = {
                'archivo': archivo,
                'columnas': columnas_permitidas  # ‚úîÔ∏è Solo columnas filtradas
            }
            return render(request, 'ver_analisis_grafico.html', contexto)

        except Exception as e:
            return render(request, 'ver_analisis_grafico.html', {
                'archivo': archivo,
                'columnas': [],
                'error': str(e)
            })


"""
def analisis_grafico(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    df = pd.read_csv(archivo.archivo.path, sep=';', on_bad_lines='skip')
    columnas = df.columns.tolist()

    x = request.GET.get('x')
    y = request.GET.get('y')
    tipo = request.GET.get('tipo', 'scatter')

    grafico_url = None
    error = None

    try:
        if x and y and x in df.columns and y in df.columns:
            fig, ax = plt.subplots()

            # Gr√°fico de dispersi√≥n (scatter plot)
            if tipo == 'scatter':
                df.plot.scatter(x=x, y=y, ax=ax)
            elif tipo == 'hist':
                df[y].plot.hist(ax=ax, bins=30)
            elif tipo == 'box':
                df[[y]].plot.box(ax=ax)
            else:
                raise ValueError("Tipo de gr√°fico no v√°lido")

            buf = BytesIO()
            plt.tight_layout()
            plt.savefig(buf, format='png')
            plt.close(fig)
            grafico_url = 'data:image/png;base64,' + base64.b64encode(buf.getvalue()).decode()
            buf.close()
    except Exception as e:
        error = str(e)

    context = {
        'archivo': archivo,
        'columnas': columnas,
        'grafico_url': grafico_url,
        'error': error,
        'x_seleccionada': x,
        'y_seleccionada': y,
        'tipo': tipo,
    }

    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        html = render_to_string('partials/fragmento_analisis_grafica.html', context)
        return JsonResponse({'html': html})

    return render(request, 'ver_analisis_grafico.html', context)
"""
@login_required 
def temp_analisis_grafico(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    df = pd.read_csv(archivo.archivo.path, sep=';', on_bad_lines='skip')

    # ‚úÖ Filtrar columnas eliminando las que son texto puro (object)
    columnas_texto = df.select_dtypes(include=['object', 'string']).columns.tolist()
    columnas_permitidas = [col for col in df.columns if col not in columnas_texto]

    x = request.GET.get('x')
    ys = request.GET.getlist('y')  # ‚úîÔ∏è Capturar m√∫ltiples Y
    tipo = request.GET.get('tipo', 'line')

    graficos = []
    error = None

    try:
        if not ys or not x:
            raise ValueError("Debe seleccionar un eje X y al menos una columna Y.")

        for y in ys:
            if y not in df.columns or x not in df.columns:
                continue

            fig, ax = plt.subplots()
            fig.set_size_inches(6, 4)  # ‚úÖ Ajuste de tama√±o

            # Convertir a num√©rico solo si no es fecha (para seguridad adicional)
            df[x] = pd.to_numeric(df[x], errors='coerce')
            df[y] = pd.to_numeric(df[y], errors='coerce')

            df_filtrado = df.dropna(subset=[x, y])

            if tipo == 'line':
                df_filtrado = df_filtrado.sort_values(by=x)
                ax.plot(df_filtrado[x], df_filtrado[y], marker='o')
                ax.set_title(f'Tendencia: {y} sobre {x}')
            elif tipo == 'scatter':
                ax.scatter(df_filtrado[x], df_filtrado[y])
                ax.set_title(f'Dispersi√≥n: {y} vs {x}')
            elif tipo == 'bar':
                resumen = df_filtrado.groupby(x)[y].mean().sort_values(ascending=False).head(15)
                resumen.plot(kind='bar', ax=ax, color='skyblue')
                ax.set_title(f'Promedio de {y} por {x}')
                ax.set_ylabel(f'{y} (promedio)')
                ax.set_xlabel(x)
            else:
                continue  # Si el tipo no es v√°lido, ignora

            plt.tight_layout()
            buf = BytesIO()
            plt.savefig(buf, format='png', dpi=100)  # ‚úîÔ∏è DPI adicional
            plt.close(fig)
            grafico_url = 'data:image/png;base64,' + base64.b64encode(buf.getvalue()).decode()
            buf.close()

            graficos.append(grafico_url)

        if not graficos:
            raise ValueError("No se generaron gr√°ficos. Verifique los datos.")

    except Exception as e:
        error = str(e)

    context = {
        'archivo': archivo,
        'columnas': columnas_permitidas,  # ‚úîÔ∏è Solo columnas num√©ricas
        'graficos': graficos,
        'error': error,
        'x_seleccionada': x,
        'tipo': tipo,
    }

    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        html = render_to_string('partials/fragmento_grafica.html', context)
        return JsonResponse({'html': html})

    return render(request, 'temp_ver_analisis_grafico.html', context)


@login_required
def comparacion_graficos(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    df = pd.read_csv(archivo.archivo.path, sep=';', on_bad_lines='skip')
    columnas = df.columns.tolist()

    x1 = request.GET.get('x1')
    y1 = request.GET.get('y1')
    tipo1 = request.GET.get('tipo1', 'line')

    x2 = request.GET.get('x2')
    y2 = request.GET.get('y2')
    tipo2 = request.GET.get('tipo2', 'bar')

    graficos = []
    error = None

    try:
        for x, y, tipo in [(x1, y1, tipo1), (x2, y2, tipo2)]:
            fig, ax = plt.subplots()
            if tipo == 'line':
                df.plot.line(x=x, y=y, ax=ax)
            elif tipo == 'bar':
                df.dropna(subset=[x, y]).groupby(x)[y].mean().plot(kind='bar', ax=ax)
            elif tipo == 'box':
                df[[y]].dropna().plot.box(ax=ax)
            elif tipo == 'pie':
                conteo = df[y].value_counts().head(10)
                ax.pie(conteo, labels=conteo.index, autopct='%1.1f%%')
                ax.set_ylabel("")
            else:
                raise ValueError("Tipo de gr√°fico no v√°lido")

            buf = BytesIO()
            plt.tight_layout()
            plt.savefig(buf, format='png')
            plt.close(fig)
            img_url = 'data:image/png;base64,' + base64.b64encode(buf.getvalue()).decode()
            buf.close()
            graficos.append(img_url)

    except Exception as e:
        error = str(e)

    context = {
        'archivo': archivo,
        'columnas': columnas,
        'grafico1': graficos[0] if len(graficos) > 0 else None,
        'grafico2': graficos[1] if len(graficos) > 1 else None,
        'x1': x1, 'y1': y1, 'tipo1': tipo1,
        'x2': x2, 'y2': y2, 'tipo2': tipo2,
        'error': error,
    }

    return render(request, 'comparacion_graficos.html', context)


@login_required
def graficos_avanzados(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    df = pd.read_csv(archivo.archivo.path, sep=';', on_bad_lines='skip')
    
    # ‚úÖ Filtrar columnas para quitar las de texto (object/string)
    columnas_texto = df.select_dtypes(include=['object', 'string']).columns.tolist()
    columnas_permitidas = [col for col in df.columns if col not in columnas_texto]

    modo = request.GET.get('modo')  # descripcion, comparacion, tendencia
    x = request.GET.get('x')
    y1 = request.GET.get('y1')
    y2 = request.GET.get('y2')

    grafico_url = None
    error = None

    try:
        fig, ax = plt.subplots()

        if modo == 'descripcion' and y1 in df.columns:
            df[y1] = pd.to_numeric(df[y1], errors='coerce')
            df[y1].dropna().plot.hist(ax=ax, bins=30, color='skyblue')
            ax.set_title(f"Histograma de {y1}")

        elif modo == 'comparacion' and x in df.columns and y1 in df.columns and y2 in df.columns:
            df[x] = pd.to_numeric(df[x], errors='coerce')
            df[y1] = pd.to_numeric(df[y1], errors='coerce')
            df[y2] = pd.to_numeric(df[y2], errors='coerce')
            df.dropna(subset=[x, y1, y2]).plot(x=x, y=[y1, y2], ax=ax)
            ax.set_title(f"Comparaci√≥n entre {y1} y {y2} respecto a {x}")

        elif modo == 'boxplot' and y1 in df.columns:
            df[y1] = pd.to_numeric(df[y1], errors='coerce')
            df[[y1]].dropna().plot.box(ax=ax)
            ax.set_title(f"Boxplot de {y1}")

        elif modo == 'tendencia' and x in df.columns and y1 in df.columns and y2 in df.columns:
            df[x] = pd.to_datetime(df[x], errors='coerce')
            df[y1] = pd.to_numeric(df[y1], errors='coerce')
            df[y2] = pd.to_numeric(df[y2], errors='coerce')
            df = df.dropna(subset=[x, y1, y2]).sort_values(x)
            ax.plot(df[x], df[y1], label=y1)
            ax.plot(df[x], df[y2], label=y2)
            ax.set_title(f"Tendencia: {y1} vs {y2} sobre {x}")
            ax.legend()

        else:
            raise ValueError("Par√°metros insuficientes o incorrectos")

        buf = BytesIO()
        plt.tight_layout()
        plt.savefig(buf, format='png')
        plt.close(fig)
        grafico_url = 'data:image/png;base64,' + base64.b64encode(buf.getvalue()).decode()
        buf.close()

    except Exception as e:
        error = str(e)

    context = {
        'archivo': archivo,
        'columnas': columnas_permitidas,  # ‚úîÔ∏è Solo columnas num√©ricas o convertibles
        'grafico_url': grafico_url,
        'error': error,
        'modo': modo,
        'x': x,
        'y1': y1,
        'y2': y2
    }

    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        html = render_to_string('partials/fragmento_grafico_avanzado.html', context)
        return JsonResponse({'html': html})

    return render(request, 'graficos_avanzados.html', context)

@login_required
def vista_procesamiento_archivos(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    return render(request, 'modificar_separadores.html', {'archivo': archivo})


@login_required
def procesamiento_archivos(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    filepath = archivo.archivo.path

    try:
        df = pd.read_csv(filepath, sep=';', on_bad_lines='skip', dtype=str)  # Todo como texto
        for col in df.columns:
            df[col] = df[col].astype(str).str.replace(',', '.', regex=False)  # Reemplazar comas por puntos
        df.to_csv(filepath, sep=';', index=False)  # Sobrescribe el archivo
        return JsonResponse({'success': True, 'message': 'Archivo modificado correctamente.'})
    except Exception as e:
        return JsonResponse({'success': False, 'message': str(e)})

@login_required
def ver_graficos_columnas(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    filepath = archivo.archivo.path
    df = pd.read_csv(filepath, delimiter=';', on_bad_lines='skip')

    # Eliminar fila completamente vac√≠a (si existe)
    if df.tail(1).isnull().all(axis=1).any():
        df = df.iloc[:-1]

    columnas = request.GET.getlist('columnas')
    imagenes_urls = []

    for col in columnas:
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convertir a num√©rico si se puede
            fig, ax = plt.subplots()
            df[col].dropna().plot(kind='hist', ax=ax, bins=20, title=f'Distribuci√≥n de {col}', color='skyblue')
            filename = f"{uuid.uuid4()}.png"
            path = os.path.join(settings.MEDIA_ROOT, filename)
            fig.savefig(path)
            plt.close(fig)
            imagenes_urls.append(settings.MEDIA_URL + filename)
        except Exception as e:
            print(f"Error procesando la columna {col}: {e}")

    return render(request, 'partials/graficos_multiples.html', {
        'imagenes': imagenes_urls
    })

@login_required
def ver_columnas_nulas(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = os.path.join(settings.MEDIA_ROOT, archivo.archivo.name)
    
    df = pd.read_csv(ruta)
    columnas_nulas = df.columns[df.isnull().any()].tolist()

    conteo_nulos = df.isnull().sum()
    conteo_nulos = conteo_nulos[conteo_nulos > 0]

    grafico_base64 = None

    if not conteo_nulos.empty:
        fig, ax = plt.subplots()
        conteo_nulos.plot(kind='bar', ax=ax, color='orange')
        ax.set_title('Valores nulos por columna')
        ax.set_ylabel('Cantidad de NaN')
        plt.xticks(rotation=45, ha='right')

        buffer = BytesIO()
        plt.tight_layout()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        grafico_base64 = base64.b64encode(buffer.read()).decode()
        plt.close()

    context = {
        'archivo_id': id,
        'columnas_nulas': columnas_nulas,
        'grafico': f"data:image/png;base64,{grafico_base64}" if grafico_base64 else None,
    }

    return render(request, 'ver_columnas_nulas.html', context)



@require_POST
def confirmar_eliminacion_columnas_nulas(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = os.path.join(settings.MEDIA_ROOT, archivo.archivo.name)

    df = pd.read_csv(ruta)

    # Eliminar columnas con al menos un NaN usando NumPy
    columnas_con_nan = df.columns[df.isnull().any()]
    df = df.drop(columns=columnas_con_nan)

    df.to_csv(ruta, index=False)  # Guardar los cambios

    return redirect('ver_archivo', archivo_id=id)

@login_required
def eliminar_columnas_ceros(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = archivo.archivo.path
    df = pd.read_csv(ruta, delimiter=';', on_bad_lines='skip')

    # Guardamos el dataframe original (para graficar antes)
    df_original = df.copy()

    # Contamos las columnas con solo ceros
    columnas_con_ceros = [col for col in df.columns if df[col].dtype != 'object' and (df[col] == 0).all()]
    cantidad_columnas_eliminadas = len(columnas_con_ceros)

    # Eliminamos esas columnas
    df.drop(columns=columnas_con_ceros, inplace=True)

    # Sobrescribimos el archivo CSV (eliminaci√≥n permanente)
    df.to_csv(ruta, index=False, sep=';')

    # Generamos gr√°fico de tendencia antes y despu√©s
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        y=[df_original.shape[1]],
        x=["Antes"],
        name="Columnas antes",
        mode="lines+markers",
        line=dict(color="red")
    ))

    fig.add_trace(go.Scatter(
        y=[df.shape[1]],
        x=["Despu√©s"],
        name="Columnas despu√©s",
        mode="lines+markers",
        line=dict(color="green")
    ))

    grafico_html = fig.to_html(full_html=False)

    return render(request, 'eliminar_columnas_ceros.html', {
        'archivo': archivo,
        'cant_columnas_eliminadas': cantidad_columnas_eliminadas,
        'grafico_html': grafico_html
    })

@login_required
def Test_graficos(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    df = pd.read_csv(archivo.archivo.path, sep=';', on_bad_lines='skip')

    # ‚úÖ Filtrar columnas num√©ricas
    columnas_texto = df.select_dtypes(include=['object', 'string']).columns.tolist()
    columnas_permitidas = [col for col in df.columns if col not in columnas_texto]

    x = request.GET.get('x')
    ys = request.GET.getlist('y')
    tipo = request.GET.get('tipo', 'line')

    graficos = []
    error = None

    if x and ys:
        try:
            for y in ys:
                if y not in df.columns or x not in df.columns:
                    continue

                fig, ax = plt.subplots()
                fig.set_size_inches(6, 4)

                # Asegurar que son num√©ricos
                df[x] = pd.to_numeric(df[x], errors='coerce')
                df[y] = pd.to_numeric(df[y], errors='coerce')
                df_filtrado = df.dropna(subset=[x, y])

                if tipo == 'line':
                    df_filtrado = df_filtrado.sort_values(by=x)
                    ax.plot(df_filtrado[x], df_filtrado[y], marker='o')
                    ax.set_title(f'Tendencia: {y} sobre {x}')
                elif tipo == 'scatter':
                    ax.scatter(df_filtrado[x], df_filtrado[y])
                    ax.set_title(f'Dispersi√≥n: {y} vs {x}')
                elif tipo == 'bar':
                    resumen = df_filtrado.groupby(x)[y].mean().sort_values(ascending=False).head(15)
                    resumen.plot(kind='bar', ax=ax, color='skyblue')
                    ax.set_title(f'Promedio de {y} por {x}')
                    ax.set_ylabel(f'{y} (promedio)')
                    ax.set_xlabel(x)
                else:
                    continue

                plt.tight_layout()
                buf = BytesIO()
                plt.savefig(buf, format='png', dpi=100)
                grafico_url = 'data:image/png;base64,' + base64.b64encode(buf.getvalue()).decode()
                buf.close()
                plt.close(fig)

                graficos.append(grafico_url)

            if not graficos:
                raise ValueError("No se generaron gr√°ficos. Verifique los datos seleccionados.")

        except Exception as e:
            error = str(e)

    context = {
        'graficos': graficos,
        'error': error,
    }

    # ‚úÖ AJAX: devolver solo el fragmento HTML para insertar en el modal
    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        html = render_to_string('partials/fragmento_test.html', context)
        return JsonResponse({'html': html})

    # ‚úÖ Render normal (si se carga directamente la URL sin AJAX)
    context.update({
        'archivo': archivo,
        'columnas': columnas_permitidas,
        'x_seleccionada': x,
        'tipo': tipo,
    })
    return render(request, 'Test_graficos.html', context)


# Funci√≥n auxiliar para guardar nuevo archivo
def guardar_archivo_modificado(df, archivo, sufijo):
    import pandas as pd
    import os
    from django.conf import settings

    nuevo_nombre = f"{os.path.splitext(archivo.nombre)[0]}_{sufijo}.csv"
    nueva_ruta_absoluta = os.path.join(settings.MEDIA_ROOT, 'uploads', nuevo_nombre)
    
    # Usa el mismo delimitador que el archivo original (probablemente ; o ,)
    df.to_csv(nueva_ruta_absoluta, index=False, sep=';')  # <== usa sep=';' si as√≠ fue le√≠do

    return nuevo_nombre




def filtro_valores(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = archivo.archivo.path
    df = pd.read_csv(ruta, sep=None, engine='python', on_bad_lines='skip')

    columnas = request.POST.getlist("columnas")

    valor = request.POST.get('valor')
    try:
        valor = float(valor)
        df_filtrado = df[df[columnas] != valor]
        nuevo = guardar_archivo_modificado(df_filtrado, archivo, f"filtro_{columnas}_{valor}")
        return HttpResponseRedirect(reverse('interfaz_procesamiento', args=[id]))
    except:
        return HttpResponseRedirect(reverse('interfaz_procesamiento', args=[id]))


def aplicar_abs(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = archivo.archivo.path
    df = pd.read_csv(ruta, sep=None, engine='python', on_bad_lines='skip')

    columnas = request.POST.getlist("columnas")

    df[columnas] = df[columnas].abs()
    nuevo = guardar_archivo_modificado(df, archivo, f"{columnas}_abs")
    return HttpResponseRedirect(reverse('interfaz_procesamiento', args=[id]))


def aplicar_normalizacion(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = archivo.archivo.path
    df = pd.read_csv(ruta, sep=None, engine='python', on_bad_lines='skip')

    columnas = request.POST.getlist("columnas")

    col_data = df[columnas]
    df[columnas] = (col_data - col_data.min()) / (col_data.max() - col_data.min())
    nuevo = guardar_archivo_modificado(df, archivo, f"{columnas}_norm")
    return HttpResponseRedirect(reverse('interfaz_procesamiento', args=[id]))

import traceback


import seaborn as sns
import matplotlib.pyplot as plt
import io, base64

def generar_matriz_correlacion(df):
    try:
        corr = df.corr(numeric_only=True)
        if corr.empty:
            return None

        plt.figure(figsize=(8, 6))
        sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
        plt.title("Matriz de correlaci√≥n", fontsize=14)

        buf = io.BytesIO()
        plt.savefig(buf, format="png", bbox_inches="tight")
        plt.close()
        buf.seek(0)
        return base64.b64encode(buf.read()).decode("utf-8")
    except Exception as e:
        print("[ERROR] al generar matriz de correlaci√≥n:", e)
        return None



@login_required
def interfaz_procesamiento(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    ruta = archivo.archivo.path

    # Leer archivo y eliminar filas completamente vac√≠as
    df = pd.read_csv(ruta, sep=None, engine='python', on_bad_lines='skip')
    df.dropna(how='all', inplace=True)

    columnas = df.columns.tolist()
    columnas_numericas = df.select_dtypes(include='number').columns.tolist()
    

    boxplot = generar_boxplot(df)
    tendencia = generar_tendencia(df)
    
    correlacion_img = generar_matriz_correlacion(df)

    comparativo_boxplot = None
    comparativo_correlacion = None

    mensaje = None
    nuevo_archivo = None


    # === Nuevo bloque: genera comparativo autom√°ticamente si el archivo es modificado ===
    if "_" in archivo.nombre:  # Parece un archivo modificado
        try:
            # Obtener el nombre del archivo original
            nombre_original = archivo.nombre.split('_')[0] + ".csv"
            ruta_original = os.path.join(settings.MEDIA_ROOT, 'uploads', nombre_original)

            if os.path.exists(ruta_original):
                df_original = pd.read_csv(ruta_original, sep=None, engine='python', on_bad_lines='skip')
                df_original.dropna(how='all', inplace=True)

                # Generar el boxplot del archivo original
                comparativo_boxplot = generar_boxplot(df_original)
                comparativo_correlacion = generar_matriz_correlacion(df_original)
        except Exception as e:
            print("[ERROR] Al generar boxplot del archivo original:", e)


    if request.method == 'POST':
            columnas = request.POST.getlist("columnas")
            operacion = request.POST.get('operacion')
            valor_personalizado = request.POST.get('valor_personalizado')

            df_filtrado = df.copy()
            sufijos = []
            mensaje = None
            nuevo_archivo = None

            if operacion == "eliminar_negativos":
                for col in columnas:
                    if (df_filtrado[col] < 0).any():
                        df_filtrado = df_filtrado[df_filtrado[col] >= 0]
                sufijos.append("sin_negativos")

            elif operacion == "eliminar_ceros":
                for col in columnas:
                    if (df_filtrado[col] == 0).any():
                        df_filtrado = df_filtrado[df_filtrado[col] != 0]
                sufijos.append("sin_ceros")

            elif operacion == "eliminar_nulos":
                for col in columnas:
                    if df_filtrado[col].isnull().any():
                        df_filtrado = df_filtrado[df_filtrado[col].notnull()]
                sufijos.append("sin_nulos")

            elif operacion == "valor_personalizado" and valor_personalizado:
                try:
                    valor = float(valor_personalizado)
                    for col in columnas:
                        df_filtrado = df_filtrado[df_filtrado[col] != valor]
                    sufijos.append(f"sin_{valor}")
                except ValueError:
                    mensaje = "Valor personalizado inv√°lido."

            elif operacion == "abs":
                df_filtrado[columnas] = df_filtrado[columnas].abs()
                sufijos.append("abs")

            elif operacion == "normalizar":
                for col in columnas:
                    max_val = df_filtrado[col].max()
                    min_val = df_filtrado[col].min()
                    if max_val != min_val:
                        df_filtrado[col] = (df_filtrado[col] - min_val) / (max_val - min_val)
                    else:
                        mensaje = f"No se puede normalizar columna {col}: max y min son iguales."
                sufijos.append("norm")

            # Guardar nuevo archivo solo si no hay errores
            if not mensaje:
                nuevo_nombre = guardar_archivo_modificado(
                    df_filtrado, archivo, '_'.join(sufijos) + '_' + uuid.uuid4().hex[:6]
                )
                nuevo_archivo = ArchivoSubido(nombre=nuevo_nombre, archivo=os.path.join('uploads', nuevo_nombre))
                nuevo_archivo.save()
                mensaje = f"Operaci√≥n aplicada. Nuevo archivo: {nuevo_archivo.nombre}"
                
                return redirect('interfaz')
                



    context = {
        'archivo': archivo,
        'columnas': columnas,
        'columnas_numericas': columnas_numericas,
        'boxplot': boxplot,
        'tendencia': tendencia,
        'mensaje': mensaje,
        'nuevo_archivo': nuevo_archivo,
        'comparativo_boxplot': comparativo_boxplot,
        'correlacion_img': correlacion_img,
        'comparativo_correlacion': comparativo_correlacion,
    
    }
    return render(request, 'interfaz_procesamiento.html', context)


def generar_boxplot(df):
    try:
        # Filtrar solo columnas num√©ricas para el boxplot
        df_numerico = df.select_dtypes(include='number')

        if df_numerico.empty:
            return None  # No hay columnas num√©ricas para graficar

        plt.figure(figsize=(10, 5))
        sns.boxplot(data=df_numerico)
        plt.xticks(rotation=45)
        plt.tight_layout()

        buffer = io.BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        image_png = buffer.getvalue()
        buffer.close()
        plt.close()

        graphic = base64.b64encode(image_png)
        graphic = graphic.decode('utf-8')

        return graphic
    except Exception as e:
        print(f"Error generando boxplot: {e}")
        return None

def generar_tendencia(df):
    df_numerico = df.select_dtypes(include='number')

    if df_numerico.empty:
        return None

    plt.figure(figsize=(10, 4))
    df_numerico.plot(ax=plt.gca())
    plt.xlabel('√çndice')
    plt.ylabel('Valores')
    plt.title('Tendencia')
    plt.tight_layout()

    buffer = BytesIO()
    plt.savefig(buffer, format='png')
    plt.close()
    buffer.seek(0)
    imagen_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    return imagen_base64

"""
def interfaz_modelado(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    modelo_info = None
    metricas = None

    try:
        df = pd.read_csv(archivo.archivo.path, sep=None, engine='python', on_bad_lines='skip')
        df.dropna(inplace=True)
        
        # Identificar columnas num√©ricas y categ√≥ricas
        columnas_numericas = df.select_dtypes(include='number').columns.tolist()
        columnas_categoricas = df.select_dtypes(exclude='number').columns.tolist()
        
        # Convertir columnas categ√≥ricas si existen
        if columnas_categoricas:
            le = LabelEncoder()
            for col in columnas_categoricas:
                df[col] = le.fit_transform(df[col])
            columnas_numericas = df.columns.tolist()  # Ahora todas son num√©ricas

    except Exception as e:
        messages.error(request, f"Error al cargar archivo: {e}")
        return render(request, "interfaz_modelado.html", {
            "archivo": archivo,
            "columnas": [],
            "modelo_info": None,
            "metricas": None
        })

    if request.method == "POST":
        columna_objetivo = request.POST.get("columna_objetivo")
        columnas_predictoras = request.POST.getlist("columnas_predictoras")
        valor_str = request.POST.get("valor", "").strip()

        # Validaciones
        if not columna_objetivo:
            messages.error(request, "Debes seleccionar una columna objetivo.")
            return render(request, "interfaz_modelado.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None
            })

        if not columnas_predictoras:
            messages.error(request, "Debes seleccionar al menos una columna predictora.")
            return render(request, "interfaz_modelado.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None
            })

        if columna_objetivo in columnas_predictoras:
            messages.error(request, "La columna objetivo no puede estar entre las predictoras.")
            return render(request, "interfaz_modelado.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None
            })

        try:
            # Preparar datos
            X = df[columnas_predictoras]
            y = df[columna_objetivo]
            
            # Entrenar modelo
            modelo = RandomForestRegressor(n_estimators=100, random_state=42)
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            modelo.fit(X_train, y_train)
            
            # Calcular m√©tricas
            y_pred = modelo.predict(X_test)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            metricas = {
                'mae': round(mae, 4),
                'r2': round(r2, 4),
                'n_estimators': modelo.n_estimators,
                'features_importances': sorted(
                    zip(columnas_predictoras, modelo.feature_importances_),
                    key=lambda x: x[1],
                    reverse=True
                )
            }
            
            modelo_info = f"Modelo RandomForest entrenado para predecir '{columna_objetivo}' usando {len(columnas_predictoras)} predictores."
            
            # Hacer predicci√≥n si se proporcionan valores
            if valor_str:
                try:
                    nuevo_valor = [float(v.strip()) for v in valor_str.split(",")]
                    if len(nuevo_valor) != len(columnas_predictoras):
                        messages.error(
                            request,
                            f"Debes ingresar {len(columnas_predictoras)} valores separados por coma (uno por cada predictor)."
                        )
                    else:
                        prediccion = modelo.predict([nuevo_valor])[0]
                        messages.success(
                            request,
                            f"Predicci√≥n para '{columna_objetivo}': {prediccion:.4f}"
                        )
                except ValueError:
                    messages.error(request, "Los valores de entrada deben ser n√∫meros separados por comas.")
                
        except Exception as e:
            messages.error(request, f"Error durante el modelado: {str(e)}")

    return render(request, "interfaz_modelado.html", {
        "archivo": archivo,
        "columnas": columnas_numericas,
        "modelo_info": modelo_info,
        "metricas": metricas
    })
"""
from django.shortcuts import render, get_object_or_404
from django.contrib import messages
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
import random
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import io, base64
import seaborn as sns

import json
from io import StringIO
#nueva parte
import statsmodels
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import warnings
warnings.filterwarnings('ignore')
#cross validation y learning curve
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import learning_curve
#Grid mejores valores para las variables
from sklearn.model_selection import GridSearchCV

from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, accuracy_score, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LinearRegression


def interfaz_modelado(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    modelo_info = None
    metricas = None
    scatter_img = None
    displot_img = None
    crosscorrelation_img = None
    df_predicciones = None
    df_parcial_predicciones = None
    es_clasificacion = False
    feature_importances_img = None
    df_predicciones_html= None

    try:
        df = pd.read_csv(archivo.archivo.path, sep=None, engine='python', on_bad_lines='skip')
        df.dropna(inplace=True)
        columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()
    except Exception as e:
        messages.error(request, f"Error al cargar archivo: {e}")
        return render(request, "interfaz_modelado.html", {
            "archivo": archivo,
            "columnas": [],
        })
    if request.method == "POST":
        tipo_modelo = request.POST.get("tipo_modelo", "randomforest")
    else:
        tipo_modelo = "randomforest"   # valor inicial por defecto

    
    if request.method == "POST":
        tipo_modelo = request.POST.get("tipo_modelo")  # üîπ RandomForest o Lineal
        columna_objetivo = request.POST.get("columna_objetivo")
        columnas_predictoras = request.POST.getlist("columnas_predictoras")

        if not columna_objetivo or columna_objetivo not in df.columns:
            messages.error(request, "Columna objetivo inv√°lida.")
            return render(request, "interfaz_modelado.html", {"archivo": archivo, "columnas": columnas_numericas})

        if not columnas_predictoras:
            messages.error(request, "Debes seleccionar al menos una columna predictora.")
            return render(request, "interfaz_modelado.html", {"archivo": archivo, "columnas": columnas_numericas})

        # ------------------------------------------------------
        # üîπ Caso 1: Modelo Lineal
        # ------------------------------------------------------
        if tipo_modelo == "lineal":
            try:
                X = df[columnas_predictoras].apply(pd.to_numeric, errors="coerce").dropna()
                y = df[columna_objetivo].apply(pd.to_numeric, errors="coerce").dropna()
                X, y = X.align(y, join="inner", axis=0)

                # Obtener par√°metros desde el formulario
                n_jobs = request.POST.get("n_jobs")
                n_jobs = int(n_jobs) if n_jobs and n_jobs.strip() != "" else None

                # Crear y entrenar el modelo
                modelo = LinearRegression(n_jobs=n_jobs)
                modelo.fit(X, y)
                y_pred = modelo.predict(X)

                # M√©tricas
                mae = mean_absolute_error(y, y_pred)
                r2 = r2_score(y, y_pred)
                metricas = {"mae": round(mae, 4), "r2": round(r2, 4)}

                # Info del modelo
                modelo_info = (
                    f"Modelo de Regresi√≥n Lineal (OLS - Ordinary Least Squares) "
                    f"entrenado para predecir '{columna_objetivo}' usando {len(columnas_predictoras)} predictores."
                )

                # Gr√°fico real vs predicho
                fig, ax = plt.subplots(figsize=(8, 5))
                ax.scatter(y, y_pred, alpha=0.6, label="Predicciones")
                ax.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', label="Ideal")
                ax.set_xlabel("Valores reales")
                ax.set_ylabel("Predicciones")
                ax.set_title("Comparaci√≥n Real vs Predicho (Lineal)")
                ax.legend()

                buf = io.BytesIO()
                plt.savefig(buf, format="png", bbox_inches="tight")
                buf.seek(0)
                scatter_img = base64.b64encode(buf.getvalue()).decode("utf-8")
                plt.close(fig)

            except Exception as e:
                messages.error(request, f"Error en el modelo lineal: {str(e)}")

        # ------------------------------------------------------
        # üîπ Caso 2: RandomForest
        # ------------------------------------------------------
        elif tipo_modelo == "randomforest":
            try:
                
                # Variables para estad√≠sticas
                total_filas = 0
                conocidos_filas = 0
                predichos_filas = 0
                error_promedio = 0
                accuracy_parcial = 0
                

                # Valores por defecto de los par√°metros
                parametros = {
                    'test_size': 0.2,
                    'random_state_split': 42,
                    'n_estimators': 100,
                    'random_state_model': 42,
                    'max_depth': None,
                    'min_samples_split': 2,
                    'min_samples_leaf': 1
                }
                
                # Valores para mostrar en la plantilla
                test_size_percent = 20
                train_size_percent = 80

                try:
                    
                    # Identificar columnas num√©ricas y categ√≥ricas
                    columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()
                    columnas_categoricas = df.select_dtypes(exclude=['number']).columns.tolist()
                    
                    # Convertir columnas categ√≥ricas si existen
                    if columnas_categoricas:
                        for col in columnas_categoricas:
                            le = LabelEncoder()
                            df[col] = le.fit_transform(df[col].astype(str))
                        columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()

                except Exception as e:
                    messages.error(request, f"Error al cargar archivo: {e}")
                    return render(request, "interfaz_modelado.html", {
                        "archivo": archivo,
                        "columnas": [],
                        "modelo_info": None,
                        "metricas": None,
                        "df_predicciones": None,
                        "df_parcial_predicciones": None,
                        "total_filas": total_filas,
                        "conocidos_filas": conocidos_filas,
                        "predichos_filas": predichos_filas,
                        "error_promedio": error_promedio,
                        "accuracy_parcial": accuracy_parcial,
                        "parametros": parametros,
                        "test_size_percent": test_size_percent,
                        "train_size_percent": train_size_percent
                    })

                if request.method == "POST":
                    columna_objetivo = request.POST.get("columna_objetivo")
                    columnas_predictoras = request.POST.getlist("columnas_predictoras")
                    valor_str = request.POST.get("valor", "").strip()
                    predecir_columna = request.POST.get("predecir_columna") == "on"
                    predecir_parcial = request.POST.get("predecir_parcial") == "on"
                    porcentaje_datos = float(request.POST.get("porcentaje_datos", 50))
                    numeric_df = df.select_dtypes(include=[np.number])

                    # Obtener par√°metros ajustables del usuario
                    try:
                        # test_size como porcentaje
                        test_size_percent = float(request.POST.get("test_size", 20))
                        parametros['test_size'] = test_size_percent / 100.0
                        train_size_percent = 100 - test_size_percent
                        
                        # Par√°metros principales
                        parametros['random_state_split'] = int(request.POST.get("random_state_split", 42))
                        parametros['n_estimators'] = int(request.POST.get("n_estimators", 100))
                        parametros['random_state_model'] = int(request.POST.get("random_state_model", 42))
                        
                        # Par√°metros avanzados
                        max_depth_str = request.POST.get("max_depth", "")
                        parametros['max_depth'] = int(max_depth_str) if max_depth_str and max_depth_str != "None" else None
                        
                        parametros['min_samples_split'] = int(request.POST.get("min_samples_split", 2))
                        parametros['min_samples_leaf'] = int(request.POST.get("min_samples_leaf", 1))
                        
                    except (ValueError, TypeError):
                        messages.warning(request, "Par√°metros inv√°lidos, usando valores por defecto.")
                        parametros = {
                            'test_size': 0.2,
                            'random_state_split': 42,
                            'n_estimators': 100,
                            'random_state_model': 42,
                            'max_depth': None,
                            'min_samples_split': 2,
                            'min_samples_leaf': 1
                        }
                        test_size_percent = 20
                        train_size_percent = 80
                    
                

                    # Validaciones
                    if not columna_objetivo or columna_objetivo not in df.columns:
                        messages.error(request, "Debes seleccionar una columna objetivo v√°lida.")
                        return render(request, "interfaz_modelado.html", {
                            "archivo": archivo,
                            "columnas": columnas_numericas,
                            "modelo_info": None,
                            "metricas": None,
                            "df_predicciones": None,
                            "df_parcial_predicciones": None,
                            "total_filas": total_filas,
                            "conocidos_filas": conocidos_filas,
                            "predichos_filas": predichos_filas,
                            "error_promedio": error_promedio,
                            "accuracy_parcial": accuracy_parcial,
                            "parametros": parametros,
                            "test_size_percent": test_size_percent,
                            "train_size_percent": train_size_percent
                        })

                    if not columnas_predictoras or not all(col in df.columns for col in columnas_predictoras):
                        messages.error(request, "Debes seleccionar columnas predictoras v√°lidas.")
                        return render(request, "interfaz_modelado.html", {
                            "archivo": archivo,
                            "columnas": columnas_numericas,
                            "modelo_info": None,
                            "metricas": None,
                            "df_predicciones": None,
                            "df_parcial_predicciones": None,
                            "total_filas": total_filas,
                            "conocidos_filas": conocidos_filas,
                            "predichos_filas": predichos_filas,
                            "error_promedio": error_promedio,
                            "accuracy_parcial": accuracy_parcial,
                            "parametros": parametros,
                            "test_size_percent": test_size_percent,
                            "train_size_percent": train_size_percent
                        })

                    if columna_objetivo in columnas_predictoras:
                        messages.error(request, "La columna objetivo no puede estar entre las predictoras.")
                        return render(request, "interfaz_modelado.html", {
                            "archivo": archivo,
                            "columnas": columnas_numericas,
                            "modelo_info": None,
                            "metricas": None,
                            "df_predicciones": None,
                            "df_parcial_predicciones": None,
                            "total_filas": total_filas,
                            "conocidos_filas": conocidos_filas,
                            "predichos_filas": predichos_filas,
                            "error_promedio": error_promedio,
                            "accuracy_parcial": accuracy_parcial,
                            "parametros": parametros,
                            "test_size_percent": test_size_percent,
                            "train_size_percent": train_size_percent
                        })

                    try:
                        # Preparar datos
                        X = df[columnas_predictoras].apply(pd.to_numeric, errors='coerce')
                        y = df[columna_objetivo].apply(pd.to_numeric, errors='coerce')
                        
                        # Eliminar filas con NaN
                        mask = ~(X.isna().any(axis=1) | y.isna())
                        X = X[mask]
                        y = y[mask]
                        
                        if len(X) == 0:
                            messages.error(request, "No hay datos v√°lidos despu√©s de la limpieza.")
                            return render(request, "interfaz_modelado.html", {
                                "archivo": archivo,
                                "columnas": columnas_numericas,
                                "modelo_info": None,
                                "metricas": None,
                                "df_predicciones": None,
                                "df_parcial_predicciones": None,
                                "total_filas": total_filas,
                                "conocidos_filas": conocidos_filas,
                                "predichos_filas": predichos_filas,
                                "error_promedio": error_promedio,
                                "accuracy_parcial": accuracy_parcial,
                                "parametros": parametros,
                                "test_size_percent": test_size_percent,
                                "train_size_percent": train_size_percent
                            })
                        
                        # Determinar si es problema de clasificaci√≥n o regresi√≥n
                        if y.nunique() <= 10:
                            es_clasificacion = True
                            modelo = RandomForestClassifier(
                                n_estimators=parametros['n_estimators'],
                                random_state=parametros['random_state_model'],
                                max_depth=parametros['max_depth'],
                                min_samples_split=parametros['min_samples_split'],
                                min_samples_leaf=parametros['min_samples_leaf']
                            )
                        else:
                            modelo = RandomForestRegressor(
                                n_estimators=parametros['n_estimators'],
                                random_state=parametros['random_state_model'],
                                max_depth=parametros['max_depth'],
                                min_samples_split=parametros['min_samples_split'],
                                min_samples_leaf=parametros['min_samples_leaf']
                            )
                        
                        param_grid = {
                            "n_estimators": [50, 100],
                            "max_depth": [None, 10, 20],
                            "min_samples_split": [2, 5],
                            "min_samples_leaf": [1, 2]
                        }

                        if y.nunique() <= 10:
                            es_clasificacion = True
                            base_model = RandomForestClassifier(random_state=parametros['random_state_model'])
                            scoring = "accuracy"
                        else:
                            base_model = RandomForestRegressor(random_state=parametros['random_state_model'])
                            scoring = "r2"

                        grid_search = GridSearchCV(
                            base_model,
                            param_grid,
                            cv=5,
                            scoring=scoring,
                            n_jobs=-1
                        )

                        grid_search.fit(X, y)
                        best_params = grid_search.best_params_
                        best_score = grid_search.best_score_
                        modelo = grid_search.best_estimator_

                        
                        # Entrenar modelo
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, 
                            test_size=parametros['test_size'],
                            random_state=parametros['random_state_split']
                        )
                        
                        modelo.fit(X_train, y_train)
                        
                        # Calcular m√©tricas
                        y_pred = modelo.predict(X_test)
                        

                        # Crear gr√°fico scatter solo si es regresi√≥n
                        if not es_clasificacion:
                            try:
                                fig, ax = plt.subplots(figsize=(12, 6))

                                # Eje X como √≠ndice temporal
                                x_axis = range(len(y_test))

                                # Puntos de valores reales
                                ax.scatter(x_axis, y_test.values, label="Datos reales", color="blue", alpha=0.6, s=30)

                                # Puntos de predicci√≥n
                                ax.scatter(x_axis, y_pred, label="Predicci√≥n", color="green", alpha=0.6, s=30)

                                ax.set_xlabel("Tiempo (√≠ndice de muestra)")
                                ax.set_ylabel(columna_objetivo)
                                ax.set_title(f"Comparaci√≥n de valores reales vs predichos ({columna_objetivo})")
                                ax.legend()

                                # Guardar como imagen base64
                                buf = io.BytesIO()
                                plt.tight_layout()
                                plt.savefig(buf, format="png")
                                plt.close(fig)
                                buf.seek(0)
                                scatter_img = base64.b64encode(buf.getvalue()).decode("utf-8")

                                # Generar gr√°fico displot (real vs predicho)
                                fig, ax = plt.subplots(figsize=(8, 5))
                                sns.histplot(y_test, color="blue", kde=True, label="Real", stat="density", ax=ax, alpha=0.4)
                                sns.histplot(y_pred, color="green", kde=True, label="Predicho", stat="density", ax=ax, alpha=0.4)
                                ax.set_title("Distribuci√≥n Real vs Predicho")
                                ax.set_xlabel("Valores")
                                ax.set_ylabel("Densidad")
                                ax.legend()

                                # Convertir a base64
                                buffer = io.BytesIO()
                                plt.savefig(buffer, format="png", bbox_inches="tight")
                                buffer.seek(0)
                                displot_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                                plt.close(fig)

                                # Gr√°fico de correlaci√≥n cruzada (50% de los datos)
                                df_comparacion = pd.DataFrame({
                                    "√çndice": range(len(y_test)),
                                    "y_real": y_test,
                                    "y_pred": y_pred
                                })
                                #importancia de variables
                                


                                # Tomar el 50% aleatorio
                                df_sample = df_comparacion.sample(frac=0.5, random_state=42)

                                fig, ax = plt.subplots(figsize=(8, 5))
                                sns.scatterplot(x="√çndice", y="y_real", data=df_sample, ax=ax, color="orange", label="Real")
                                sns.scatterplot(x="√çndice", y="y_pred", data=df_sample, ax=ax, color="blue", label="Predicho")

                                ax.set_title(f"Comparaci√≥n Real vs Predicho ({columna_objetivo}) - Muestra 50%")
                                ax.set_xlabel("√çndice (muestra)")
                                ax.set_ylabel("Valor")
                                ax.legend()

                                buffer = io.BytesIO()
                                fig.savefig(buffer, format="png", bbox_inches="tight")
                                buffer.seek(0)
                                crosscorrelation_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                                plt.close(fig)

                            except Exception as e:
                                print("Error al generar gr√°fico:", e)

                        if es_clasificacion:
                            accuracy = accuracy_score(y_test, y_pred)
                            scores = cross_val_score(base_model, X, y, cv=5, scoring=scoring)
                            cv_mean, cv_std = scores.mean(), scores.std()
                            # üîπ Importancia de variables (solo si el modelo lo soporta)
                            if hasattr(modelo, "feature_importances_"):
                                try:
                                    importances = modelo.feature_importances_
                                    features = columnas_predictoras

                                    fig, ax = plt.subplots(figsize=(8, 5))
                                    sns.barplot(x=importances, y=features, ax=ax, palette="viridis")
                                    ax.set_title("Importancia de Variables")
                                    ax.set_xlabel("Importancia")
                                    ax.set_ylabel("Variables")

                                    buffer = io.BytesIO()
                                    plt.savefig(buffer, format="png", bbox_inches="tight")
                                    buffer.seek(0)
                                    feature_importances_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                                    plt.close(fig)
                                except Exception as e:
                                    print("Error al generar gr√°fico de importancia:", e)
                            metricas = {
                                'accuracy': round(accuracy, 4),
                                'classification_report': classification_report(y_test, y_pred),
                                'n_estimators': modelo.n_estimators,
                                'features_importances': sorted(
                                    zip(columnas_predictoras, modelo.feature_importances_),
                                    key=lambda x: x[1],
                                    reverse=True
                                ),
                                'tipo': 'clasificaci√≥n',
                                'test_size': parametros['test_size'],
                                'test_size_percent': test_size_percent,
                                'random_state_split': parametros['random_state_split'],
                                'random_state_model': parametros['random_state_model'],
                                'max_depth': parametros['max_depth'],
                                'min_samples_split': parametros['min_samples_split'],
                                'min_samples_leaf': parametros['min_samples_leaf'],
                                "best_params": best_params,
                                "best_score": round(best_score, 4),
                                "cv_mean": round(cv_mean, 4),
                                "cv_std": round(cv_std, 4),
                            }
                        else:
                            mae = mean_absolute_error(y_test, y_pred)
                            r2 = r2_score(y_test, y_pred)
                            metricas = {
                                'mae': round(mae, 4),
                                'r2': round(r2, 4),
                                'n_estimators': modelo.n_estimators,
                                'features_importances': sorted(
                                    zip(columnas_predictoras, modelo.feature_importances_),
                                    key=lambda x: x[1],
                                    reverse=True
                                ),
                                'tipo': 'regresi√≥n',
                                'test_size': parametros['test_size'],
                                'test_size_percent': test_size_percent,
                                'random_state_split': parametros['random_state_split'],
                                'random_state_model': parametros['random_state_model'],
                                'max_depth': parametros['max_depth'],
                                'min_samples_split': parametros['min_samples_split'],
                                'min_samples_leaf': parametros['min_samples_leaf']
                            }
                        
                        modelo_info = f"Modelo RandomForest entrenado para predecir '{columna_objetivo}' usando {len(columnas_predictoras)} predictores."
                        
                        # Hacer predicci√≥n si se proporcionan valores
                        if valor_str:
                            try:
                                nuevo_valor = [float(v.strip()) for v in valor_str.split(",")]
                                if len(nuevo_valor) != len(columnas_predictoras):
                                    messages.error(
                                        request,
                                        f"Debes ingresar {len(columnas_predictoras)} valores separados por coma (uno por cada predictor)."
                                    )
                                else:
                                    prediccion = modelo.predict([nuevo_valor])[0]
                                    messages.success(
                                        request,
                                        f"Predicci√≥n para '{columna_objetivo}': {prediccion:.4f}"
                                    )
                            except ValueError:
                                messages.error(request, "Los valores de entrada deben ser n√∫meros separados por comas.")
                        
                        # Predecir columna completa
                        if predecir_columna:
                            predicciones = modelo.predict(X)
                            df_predicciones = df.loc[X.index].copy()
                            df_predicciones[f'Predicci√≥n_{columna_objetivo}'] = predicciones
                            df_predicciones['Error'] = np.abs(y.values - predicciones) if not es_clasificacion else (y.values != predicciones).astype(int)
                            messages.success(request, f"Se han generado predicciones para {len(df_predicciones)} filas.")
                        
                        # Predicci√≥n parcial de datos
                        if predecir_parcial:
                            n_filas = len(X)
                            n_entrenamiento = int(n_filas * (porcentaje_datos / 100))
                            indices = X.index.tolist()
                            random.shuffle(indices)
                            indices_con_target = indices[:n_entrenamiento]
                            indices_sin_target = indices[n_entrenamiento:]
                            
                            if not indices_sin_target:
                                messages.warning(request, "No hay datos para predecir con el porcentaje seleccionado.")
                            else:
                                # Entrenar modelo solo con datos conocidos
                                X_conocido = X.loc[indices_con_target]
                                y_conocido = y.loc[indices_con_target]
                                
                                if es_clasificacion:
                                    modelo_parcial = RandomForestClassifier(
                                        n_estimators=parametros['n_estimators'],
                                        random_state=parametros['random_state_model'],
                                        max_depth=parametros['max_depth'],
                                        min_samples_split=parametros['min_samples_split'],
                                        min_samples_leaf=parametros['min_samples_leaf']
                                    )
                                else:
                                    modelo_parcial = RandomForestRegressor(
                                        n_estimators=parametros['n_estimators'],
                                        random_state=parametros['random_state_model'],
                                        max_depth=parametros['max_depth'],
                                        min_samples_split=parametros['min_samples_split'],
                                        min_samples_leaf=parametros['min_samples_leaf']
                                    )
                                
                                modelo_parcial.fit(X_conocido, y_conocido)
                                predicciones_todas = modelo_parcial.predict(X)
                                
                                df_parcial_predicciones = df.loc[X.index].copy()
                                df_parcial_predicciones[f'Predicci√≥n_{columna_objetivo}'] = predicciones_todas
                                
                                if es_clasificacion:
                                    df_parcial_predicciones['Error'] = (y.values != predicciones_todas).astype(int)
                                else:
                                    df_parcial_predicciones['Error'] = np.abs(y.values - predicciones_todas)
                                
                                df_parcial_predicciones['Tipo'] = 'Predicho'
                                df_parcial_predicciones.loc[indices_con_target, 'Tipo'] = 'Conocido (Entrenamiento)'
                                
                                total_filas = len(df_parcial_predicciones)
                                conocidos_filas = len(indices_con_target)
                                predichos_filas = len(indices_sin_target)
                                if df_predicciones is not None:
                                    df_predicciones_html = df_predicciones.head(20).to_html(classes="table table-striped table-sm", index=False)
                                else:
                                    df_predicciones_html = None
                                if conocidos_filas > 0:
                                    datos_entrenamiento = df_parcial_predicciones.loc[indices_con_target]
                                    if es_clasificacion:
                                        correctos = len(datos_entrenamiento[datos_entrenamiento['Error'] == 0])
                                        accuracy_parcial = round((correctos / conocidos_filas) * 100, 2)
                                    else:
                                        error_promedio = round(datos_entrenamiento['Error'].mean(), 4)
                                
                                messages.success(request, f"Predicci√≥n parcial completada. {conocidos_filas} filas para entrenamiento, {predichos_filas} filas predichas.")
                            
                    except Exception as e:
                        messages.error(request, f"Error durante el modelado: {str(e)}")
                        import traceback
                        traceback.print_exc()

            except Exception as e:
                messages.error(request, f"Error en el modelo RandomForest: {str(e)}")

    return render(request, "interfaz_modelado.html", {
        "archivo": archivo,
        "columnas": columnas_numericas,
        "modelo_info": modelo_info,
        "metricas": metricas,
        "scatter_img": scatter_img,
        "displot_img": displot_img,
        "crosscorrelation_img": crosscorrelation_img,
        "df_predicciones": df_predicciones,
        "df_parcial_predicciones": df_parcial_predicciones,
        "es_clasificacion": es_clasificacion,
        "tipo_modelo": tipo_modelo,
        "feature_importances_img": feature_importances_img,
        "df_predicciones": df_predicciones_html,

    })
"""
def interfaz_modelado(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    modelo_info = None
    metricas = None
    df_predicciones = None
    df_parcial_predicciones = None
    es_clasificacion = False
    scatter_img = None
    displot_img = None
    crosscorrelation_img = None
    feature_importances_img = None

    # Variables para estad√≠sticas
    total_filas = 0
    conocidos_filas = 0
    predichos_filas = 0
    error_promedio = 0
    accuracy_parcial = 0
    

    # Valores por defecto de los par√°metros
    parametros = {
        'test_size': 0.2,
        'random_state_split': 42,
        'n_estimators': 100,
        'random_state_model': 42,
        'max_depth': None,
        'min_samples_split': 2,
        'min_samples_leaf': 1
    }
    
    # Valores para mostrar en la plantilla
    test_size_percent = 20
    train_size_percent = 80

    try:
        df = pd.read_csv(archivo.archivo.path, sep=None, engine='python', on_bad_lines='skip')
        df.dropna(inplace=True)
        
        # Identificar columnas num√©ricas y categ√≥ricas
        columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()
        columnas_categoricas = df.select_dtypes(exclude=['number']).columns.tolist()
        
        # Convertir columnas categ√≥ricas si existen
        if columnas_categoricas:
            for col in columnas_categoricas:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
            columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()

    except Exception as e:
        messages.error(request, f"Error al cargar archivo: {e}")
        return render(request, "interfaz_modelado.html", {
            "archivo": archivo,
            "columnas": [],
            "modelo_info": None,
            "metricas": None,
            "df_predicciones": None,
            "df_parcial_predicciones": None,
            "total_filas": total_filas,
            "conocidos_filas": conocidos_filas,
            "predichos_filas": predichos_filas,
            "error_promedio": error_promedio,
            "accuracy_parcial": accuracy_parcial,
            "parametros": parametros,
            "test_size_percent": test_size_percent,
            "train_size_percent": train_size_percent
        })

    if request.method == "POST":
        columna_objetivo = request.POST.get("columna_objetivo")
        columnas_predictoras = request.POST.getlist("columnas_predictoras")
        valor_str = request.POST.get("valor", "").strip()
        predecir_columna = request.POST.get("predecir_columna") == "on"
        predecir_parcial = request.POST.get("predecir_parcial") == "on"
        porcentaje_datos = float(request.POST.get("porcentaje_datos", 50))
        numeric_df = df.select_dtypes(include=[np.number])

        # Obtener par√°metros ajustables del usuario
        try:
            # test_size como porcentaje
            test_size_percent = float(request.POST.get("test_size", 20))
            parametros['test_size'] = test_size_percent / 100.0
            train_size_percent = 100 - test_size_percent
            
            # Par√°metros principales
            parametros['random_state_split'] = int(request.POST.get("random_state_split", 42))
            parametros['n_estimators'] = int(request.POST.get("n_estimators", 100))
            parametros['random_state_model'] = int(request.POST.get("random_state_model", 42))
            
            # Par√°metros avanzados
            max_depth_str = request.POST.get("max_depth", "")
            parametros['max_depth'] = int(max_depth_str) if max_depth_str and max_depth_str != "None" else None
            
            parametros['min_samples_split'] = int(request.POST.get("min_samples_split", 2))
            parametros['min_samples_leaf'] = int(request.POST.get("min_samples_leaf", 1))
            
        except (ValueError, TypeError):
            messages.warning(request, "Par√°metros inv√°lidos, usando valores por defecto.")
            parametros = {
                'test_size': 0.2,
                'random_state_split': 42,
                'n_estimators': 100,
                'random_state_model': 42,
                'max_depth': None,
                'min_samples_split': 2,
                'min_samples_leaf': 1
            }
            test_size_percent = 20
            train_size_percent = 80
        
    

        # Validaciones
        if not columna_objetivo or columna_objetivo not in df.columns:
            messages.error(request, "Debes seleccionar una columna objetivo v√°lida.")
            return render(request, "interfaz_modelado.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "df_predicciones": None,
                "df_parcial_predicciones": None,
                "total_filas": total_filas,
                "conocidos_filas": conocidos_filas,
                "predichos_filas": predichos_filas,
                "error_promedio": error_promedio,
                "accuracy_parcial": accuracy_parcial,
                "parametros": parametros,
                "test_size_percent": test_size_percent,
                "train_size_percent": train_size_percent
            })

        if not columnas_predictoras or not all(col in df.columns for col in columnas_predictoras):
            messages.error(request, "Debes seleccionar columnas predictoras v√°lidas.")
            return render(request, "interfaz_modelado.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "df_predicciones": None,
                "df_parcial_predicciones": None,
                "total_filas": total_filas,
                "conocidos_filas": conocidos_filas,
                "predichos_filas": predichos_filas,
                "error_promedio": error_promedio,
                "accuracy_parcial": accuracy_parcial,
                "parametros": parametros,
                "test_size_percent": test_size_percent,
                "train_size_percent": train_size_percent
            })

        if columna_objetivo in columnas_predictoras:
            messages.error(request, "La columna objetivo no puede estar entre las predictoras.")
            return render(request, "interfaz_modelado.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "df_predicciones": None,
                "df_parcial_predicciones": None,
                "total_filas": total_filas,
                "conocidos_filas": conocidos_filas,
                "predichos_filas": predichos_filas,
                "error_promedio": error_promedio,
                "accuracy_parcial": accuracy_parcial,
                "parametros": parametros,
                "test_size_percent": test_size_percent,
                "train_size_percent": train_size_percent
            })

        try:
            # Preparar datos
            X = df[columnas_predictoras].apply(pd.to_numeric, errors='coerce')
            y = df[columna_objetivo].apply(pd.to_numeric, errors='coerce')
            
            # Eliminar filas con NaN
            mask = ~(X.isna().any(axis=1) | y.isna())
            X = X[mask]
            y = y[mask]
            
            if len(X) == 0:
                messages.error(request, "No hay datos v√°lidos despu√©s de la limpieza.")
                return render(request, "interfaz_modelado.html", {
                    "archivo": archivo,
                    "columnas": columnas_numericas,
                    "modelo_info": None,
                    "metricas": None,
                    "df_predicciones": None,
                    "df_parcial_predicciones": None,
                    "total_filas": total_filas,
                    "conocidos_filas": conocidos_filas,
                    "predichos_filas": predichos_filas,
                    "error_promedio": error_promedio,
                    "accuracy_parcial": accuracy_parcial,
                    "parametros": parametros,
                    "test_size_percent": test_size_percent,
                    "train_size_percent": train_size_percent
                })
            
            # Determinar si es problema de clasificaci√≥n o regresi√≥n
            if y.nunique() <= 10:
                es_clasificacion = True
                modelo = RandomForestClassifier(
                    n_estimators=parametros['n_estimators'],
                    random_state=parametros['random_state_model'],
                    max_depth=parametros['max_depth'],
                    min_samples_split=parametros['min_samples_split'],
                    min_samples_leaf=parametros['min_samples_leaf']
                )
            else:
                modelo = RandomForestRegressor(
                    n_estimators=parametros['n_estimators'],
                    random_state=parametros['random_state_model'],
                    max_depth=parametros['max_depth'],
                    min_samples_split=parametros['min_samples_split'],
                    min_samples_leaf=parametros['min_samples_leaf']
                )
            
            # Entrenar modelo
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, 
                test_size=parametros['test_size'],
                random_state=parametros['random_state_split']
            )
            
            modelo.fit(X_train, y_train)
            
            # Calcular m√©tricas
            y_pred = modelo.predict(X_test)
            

            # Crear gr√°fico scatter solo si es regresi√≥n
            if not es_clasificacion:
                try:
                    fig, ax = plt.subplots(figsize=(12, 6))

                    # Eje X como √≠ndice temporal
                    x_axis = range(len(y_test))

                    # Puntos de valores reales
                    ax.scatter(x_axis, y_test.values, label="Datos reales", color="blue", alpha=0.6, s=30)

                    # Puntos de predicci√≥n
                    ax.scatter(x_axis, y_pred, label="Predicci√≥n", color="green", alpha=0.6, s=30)

                    ax.set_xlabel("Tiempo (√≠ndice de muestra)")
                    ax.set_ylabel(columna_objetivo)
                    ax.set_title(f"Comparaci√≥n de valores reales vs predichos ({columna_objetivo})")
                    ax.legend()

                    # Guardar como imagen base64
                    buf = io.BytesIO()
                    plt.tight_layout()
                    plt.savefig(buf, format="png")
                    plt.close(fig)
                    buf.seek(0)
                    scatter_img = base64.b64encode(buf.getvalue()).decode("utf-8")

                    # Generar gr√°fico displot (real vs predicho)
                    fig, ax = plt.subplots(figsize=(8, 5))
                    sns.histplot(y_test, color="blue", kde=True, label="Real", stat="density", ax=ax, alpha=0.4)
                    sns.histplot(y_pred, color="green", kde=True, label="Predicho", stat="density", ax=ax, alpha=0.4)
                    ax.set_title("Distribuci√≥n Real vs Predicho")
                    ax.set_xlabel("Valores")
                    ax.set_ylabel("Densidad")
                    ax.legend()

                    # Convertir a base64
                    buffer = io.BytesIO()
                    plt.savefig(buffer, format="png", bbox_inches="tight")
                    buffer.seek(0)
                    displot_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                    plt.close(fig)

                    # Gr√°fico de correlaci√≥n cruzada (50% de los datos)
                    df_comparacion = pd.DataFrame({
                        "√çndice": range(len(y_test)),
                        "y_real": y_test,
                        "y_pred": y_pred
                    })
                    #importancia de variables
                    


                    # Tomar el 50% aleatorio
                    df_sample = df_comparacion.sample(frac=0.5, random_state=42)

                    fig, ax = plt.subplots(figsize=(8, 5))
                    sns.scatterplot(x="√çndice", y="y_real", data=df_sample, ax=ax, color="orange", label="Real")
                    sns.scatterplot(x="√çndice", y="y_pred", data=df_sample, ax=ax, color="blue", label="Predicho")

                    ax.set_title(f"Comparaci√≥n Real vs Predicho ({columna_objetivo}) - Muestra 50%")
                    ax.set_xlabel("√çndice (muestra)")
                    ax.set_ylabel("Valor")
                    ax.legend()

                    buffer = io.BytesIO()
                    fig.savefig(buffer, format="png", bbox_inches="tight")
                    buffer.seek(0)
                    crosscorrelation_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                    plt.close(fig)

                except Exception as e:
                    print("Error al generar gr√°fico:", e)

            if es_clasificacion:
                accuracy = accuracy_score(y_test, y_pred)
                metricas = {
                    'accuracy': round(accuracy, 4),
                    'classification_report': classification_report(y_test, y_pred),
                    'n_estimators': modelo.n_estimators,
                    'features_importances': sorted(
                        zip(columnas_predictoras, modelo.feature_importances_),
                        key=lambda x: x[1],
                        reverse=True
                    ),
                    'tipo': 'clasificaci√≥n',
                    'test_size': parametros['test_size'],
                    'test_size_percent': test_size_percent,
                    'random_state_split': parametros['random_state_split'],
                    'random_state_model': parametros['random_state_model'],
                    'max_depth': parametros['max_depth'],
                    'min_samples_split': parametros['min_samples_split'],
                    'min_samples_leaf': parametros['min_samples_leaf']
                }
            else:
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                metricas = {
                    'mae': round(mae, 4),
                    'r2': round(r2, 4),
                    'n_estimators': modelo.n_estimators,
                    'features_importances': sorted(
                        zip(columnas_predictoras, modelo.feature_importances_),
                        key=lambda x: x[1],
                        reverse=True
                    ),
                    'tipo': 'regresi√≥n',
                    'test_size': parametros['test_size'],
                    'test_size_percent': test_size_percent,
                    'random_state_split': parametros['random_state_split'],
                    'random_state_model': parametros['random_state_model'],
                    'max_depth': parametros['max_depth'],
                    'min_samples_split': parametros['min_samples_split'],
                    'min_samples_leaf': parametros['min_samples_leaf']
                }
            
            modelo_info = f"Modelo RandomForest entrenado para predecir '{columna_objetivo}' usando {len(columnas_predictoras)} predictores."
            
            # Hacer predicci√≥n si se proporcionan valores
            if valor_str:
                try:
                    nuevo_valor = [float(v.strip()) for v in valor_str.split(",")]
                    if len(nuevo_valor) != len(columnas_predictoras):
                        messages.error(
                            request,
                            f"Debes ingresar {len(columnas_predictoras)} valores separados por coma (uno por cada predictor)."
                        )
                    else:
                        prediccion = modelo.predict([nuevo_valor])[0]
                        messages.success(
                            request,
                            f"Predicci√≥n para '{columna_objetivo}': {prediccion:.4f}"
                        )
                except ValueError:
                    messages.error(request, "Los valores de entrada deben ser n√∫meros separados por comas.")
            
            # Predecir columna completa
            if predecir_columna:
                predicciones = modelo.predict(X)
                df_predicciones = df.loc[X.index].copy()
                df_predicciones[f'Predicci√≥n_{columna_objetivo}'] = predicciones
                df_predicciones['Error'] = np.abs(y.values - predicciones) if not es_clasificacion else (y.values != predicciones).astype(int)
                messages.success(request, f"Se han generado predicciones para {len(df_predicciones)} filas.")
            
            # Predicci√≥n parcial de datos
            if predecir_parcial:
                n_filas = len(X)
                n_entrenamiento = int(n_filas * (porcentaje_datos / 100))
                indices = X.index.tolist()
                random.shuffle(indices)
                indices_con_target = indices[:n_entrenamiento]
                indices_sin_target = indices[n_entrenamiento:]
                
                if not indices_sin_target:
                    messages.warning(request, "No hay datos para predecir con el porcentaje seleccionado.")
                else:
                    # Entrenar modelo solo con datos conocidos
                    X_conocido = X.loc[indices_con_target]
                    y_conocido = y.loc[indices_con_target]
                    
                    if es_clasificacion:
                        modelo_parcial = RandomForestClassifier(
                            n_estimators=parametros['n_estimators'],
                            random_state=parametros['random_state_model'],
                            max_depth=parametros['max_depth'],
                            min_samples_split=parametros['min_samples_split'],
                            min_samples_leaf=parametros['min_samples_leaf']
                        )
                    else:
                        modelo_parcial = RandomForestRegressor(
                            n_estimators=parametros['n_estimators'],
                            random_state=parametros['random_state_model'],
                            max_depth=parametros['max_depth'],
                            min_samples_split=parametros['min_samples_split'],
                            min_samples_leaf=parametros['min_samples_leaf']
                        )
                    
                    modelo_parcial.fit(X_conocido, y_conocido)
                    predicciones_todas = modelo_parcial.predict(X)
                    
                    df_parcial_predicciones = df.loc[X.index].copy()
                    df_parcial_predicciones[f'Predicci√≥n_{columna_objetivo}'] = predicciones_todas
                    
                    if es_clasificacion:
                        df_parcial_predicciones['Error'] = (y.values != predicciones_todas).astype(int)
                    else:
                        df_parcial_predicciones['Error'] = np.abs(y.values - predicciones_todas)
                    
                    df_parcial_predicciones['Tipo'] = 'Predicho'
                    df_parcial_predicciones.loc[indices_con_target, 'Tipo'] = 'Conocido (Entrenamiento)'
                    
                    total_filas = len(df_parcial_predicciones)
                    conocidos_filas = len(indices_con_target)
                    predichos_filas = len(indices_sin_target)
                    
                    if conocidos_filas > 0:
                        datos_entrenamiento = df_parcial_predicciones.loc[indices_con_target]
                        if es_clasificacion:
                            correctos = len(datos_entrenamiento[datos_entrenamiento['Error'] == 0])
                            accuracy_parcial = round((correctos / conocidos_filas) * 100, 2)
                        else:
                            error_promedio = round(datos_entrenamiento['Error'].mean(), 4)
                    
                    messages.success(request, f"Predicci√≥n parcial completada. {conocidos_filas} filas para entrenamiento, {predichos_filas} filas predichas.")
                
        except Exception as e:
            messages.error(request, f"Error durante el modelado: {str(e)}")
            import traceback
            traceback.print_exc()

    return render(request, "interfaz_modelado.html", {
        "archivo": archivo,
        "columnas": columnas_numericas,
        "modelo_info": modelo_info,
        "metricas": metricas,
        "df_predicciones": df_predicciones,
        "df_parcial_predicciones": df_parcial_predicciones,
        "es_clasificacion": es_clasificacion,
        "total_filas": total_filas,
        "conocidos_filas": conocidos_filas,
        "predichos_filas": predichos_filas,
        "error_promedio": error_promedio,
        "accuracy_parcial": accuracy_parcial,
        "parametros": parametros,
        "test_size_percent": test_size_percent,
        "train_size_percent": train_size_percent,
        "scatter_img": scatter_img,
        "displot_img": displot_img,
        "crosscorrelation_img": crosscorrelation_img,

    })
#en teoria ya nada referncia descargar_predicciones, si es asi borrar todo
    path('descargar_predicciones/<int:id>/', views.descargar_predicciones, name='descargar_predicciones'),
def descargar_predicciones(request, id):
    if request.method == "POST":
        datos_predicciones = request.POST.get("datos_predicciones")
        archivo = get_object_or_404(ArchivoSubido, id=id)
        
        try:
            df = pd.read_json(StringIO(datos_predicciones))
            response = HttpResponse(content_type='text/csv')
            response['Content-Disposition'] = f'attachment; filename="predicciones_{archivo.nombre}.csv"'
            df.to_csv(response, index=False)
            return response
            
        except Exception as e:
            messages.error(request, f"Error al generar el archivo: {str(e)}")
            return redirect('interfaz_modelado', id=id)
"""
from django.shortcuts import render, get_object_or_404
from django.contrib import messages
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
import random
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import io, base64
import seaborn as sns
#nueva parte
import statsmodels
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import warnings
warnings.filterwarnings('ignore')
#cross validation y learning curve
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import learning_curve
#Grid mejores valores para las variables
from sklearn.model_selection import GridSearchCV

def prueba_modelado_randomforest(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    modelo_info = None
    metricas = None
    df_predicciones = None
    df_parcial_predicciones = None
    es_clasificacion = False
    scatter_img = None
    displot_img = None
    crosscorrelation_img = None
    learning_curve_img = None
    feature_importances_img = None

    # Variables para estad√≠sticas
    total_filas = 0
    conocidos_filas = 0
    predichos_filas = 0
    error_promedio = 0
    accuracy_parcial = 0
    
    #grill de parametros
    # Grilla de par√°metros
    

    # Valores por defecto de los par√°metros
    parametros = {
        'test_size': 0.2,
        'random_state_split': 42,
        'n_estimators': 100,
        'random_state_model': 42,
        'max_depth': None,
        'min_samples_split': 2,
        'min_samples_leaf': 1
    }
    
    # Valores para mostrar en la plantilla
    test_size_percent = 20
    train_size_percent = 80

    try:
        df = pd.read_csv(archivo.archivo.path, sep=None, engine='python', on_bad_lines='skip')
        df.dropna(inplace=True)
        
        # Identificar columnas num√©ricas y categ√≥ricas
        columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()
        columnas_categoricas = df.select_dtypes(exclude=['number']).columns.tolist()
        
        # Convertir columnas categ√≥ricas si existen
        if columnas_categoricas:
            for col in columnas_categoricas:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
            columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()

    except Exception as e:
        messages.error(request, f"Error al cargar archivo: {e}")
        return render(request, "prueba_modelado_randomforest.html", {
            "archivo": archivo,
            "columnas": [],
            "modelo_info": None,
            "metricas": None,
            "df_predicciones": None,
            "df_parcial_predicciones": None,
            "total_filas": total_filas,
            "conocidos_filas": conocidos_filas,
            "predichos_filas": predichos_filas,
            "error_promedio": error_promedio,
            "accuracy_parcial": accuracy_parcial,
            "parametros": parametros,
            "test_size_percent": test_size_percent,
            "train_size_percent": train_size_percent
        })

    if request.method == "POST":
        columna_objetivo = request.POST.get("columna_objetivo")
        columnas_predictoras = request.POST.getlist("columnas_predictoras")
        valor_str = request.POST.get("valor", "").strip()
        predecir_columna = request.POST.get("predecir_columna") == "on"
        predecir_parcial = request.POST.get("predecir_parcial") == "on"
        porcentaje_datos = float(request.POST.get("porcentaje_datos", 50))
        numeric_df = df.select_dtypes(include=[np.number])

        # Obtener par√°metros ajustables del usuario
        try:
            # test_size como porcentaje
            test_size_percent = float(request.POST.get("test_size", 20))
            parametros['test_size'] = test_size_percent / 100.0
            train_size_percent = 100 - test_size_percent
            
            # Par√°metros principales
            parametros['random_state_split'] = int(request.POST.get("random_state_split", 42))
            parametros['n_estimators'] = int(request.POST.get("n_estimators", 100))
            parametros['random_state_model'] = int(request.POST.get("random_state_model", 42))
            
            # Par√°metros avanzados
            max_depth_str = request.POST.get("max_depth", "")
            parametros['max_depth'] = int(max_depth_str) if max_depth_str and max_depth_str != "None" else None
            
            parametros['min_samples_split'] = int(request.POST.get("min_samples_split", 2))
            parametros['min_samples_leaf'] = int(request.POST.get("min_samples_leaf", 1))
            
        except (ValueError, TypeError):
            messages.warning(request, "Par√°metros inv√°lidos, usando valores por defecto.")
            parametros = {
                'test_size': 0.2,
                'random_state_split': 42,
                'n_estimators': 100,
                'random_state_model': 42,
                'max_depth': None,
                'min_samples_split': 2,
                'min_samples_leaf': 1
            }
            test_size_percent = 20
            train_size_percent = 80
        
    

        # Validaciones
        if not columna_objetivo or columna_objetivo not in df.columns:
            messages.error(request, "Debes seleccionar una columna objetivo v√°lida.")
            return render(request, "prueba_modelado_randomforest.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "df_predicciones": None,
                "df_parcial_predicciones": None,
                "total_filas": total_filas,
                "conocidos_filas": conocidos_filas,
                "predichos_filas": predichos_filas,
                "error_promedio": error_promedio,
                "accuracy_parcial": accuracy_parcial,
                "parametros": parametros,
                "test_size_percent": test_size_percent,
                "train_size_percent": train_size_percent
            })

        if not columnas_predictoras or not all(col in df.columns for col in columnas_predictoras):
            messages.error(request, "Debes seleccionar columnas predictoras v√°lidas.")
            return render(request, "prueba_modelado_randomforest.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "df_predicciones": None,
                "df_parcial_predicciones": None,
                "total_filas": total_filas,
                "conocidos_filas": conocidos_filas,
                "predichos_filas": predichos_filas,
                "error_promedio": error_promedio,
                "accuracy_parcial": accuracy_parcial,
                "parametros": parametros,
                "test_size_percent": test_size_percent,
                "train_size_percent": train_size_percent
            })

        if columna_objetivo in columnas_predictoras:
            messages.error(request, "La columna objetivo no puede estar entre las predictoras.")
            return render(request, "prueba_modelado_randomforest.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "df_predicciones": None,
                "df_parcial_predicciones": None,
                "total_filas": total_filas,
                "conocidos_filas": conocidos_filas,
                "predichos_filas": predichos_filas,
                "error_promedio": error_promedio,
                "accuracy_parcial": accuracy_parcial,
                "parametros": parametros,
                "test_size_percent": test_size_percent,
                "train_size_percent": train_size_percent
            })

        try:
            # Preparar datos
            X = df[columnas_predictoras].apply(pd.to_numeric, errors='coerce')
            y = df[columna_objetivo].apply(pd.to_numeric, errors='coerce')
            
            # Eliminar filas con NaN
            mask = ~(X.isna().any(axis=1) | y.isna())
            X = X[mask]
            y = y[mask]
            


            if len(X) == 0:
                messages.error(request, "No hay datos v√°lidos despu√©s de la limpieza.")
                return render(request, "prueba_modelado_randomforest.html", {
                    "archivo": archivo,
                    "columnas": columnas_numericas,
                    "modelo_info": None,
                    "metricas": None,
                    "df_predicciones": None,
                    "df_parcial_predicciones": None,
                    "total_filas": total_filas,
                    "conocidos_filas": conocidos_filas,
                    "predichos_filas": predichos_filas,
                    "error_promedio": error_promedio,
                    "accuracy_parcial": accuracy_parcial,
                    "parametros": parametros,
                    "test_size_percent": test_size_percent,
                    "train_size_percent": train_size_percent
                })
            

            param_grid = {
                "n_estimators": [50, 100],
                "max_depth": [None, 10, 20],
                "min_samples_split": [2, 5],
                "min_samples_leaf": [1, 2]
            }

            # Determinar si es problema de clasificaci√≥n o regresi√≥n
            if y.nunique() <= 10:
                es_clasificacion = True
                modelo = RandomForestClassifier(random_state=parametros['random_state_model'])
                scoring = "accuracy"
            else:
                modelo = RandomForestRegressor(random_state=parametros['random_state_model'])
                scoring = "r2"
            
            grid_search = GridSearchCV(
                modelo,
                param_grid,
                cv=5,
                scoring=scoring,
                n_jobs=-1
            )

            grid_search.fit(X, y)

            # Extraer mejores par√°metros y modelo
            best_params = grid_search.best_params_
            best_score = grid_search.best_score_
            modelo = grid_search.best_estimator_

            # Entrenar modelo
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, 
                test_size=parametros['test_size'],
                random_state=parametros['random_state_split']
            )
            
            modelo.fit(X_train, y_train)
            
            # learning curve
            try:
                train_sizes, train_scores, test_scores = learning_curve(
                    modelo, X, y, cv=5, scoring="r2",
                    train_sizes=np.linspace(0.1, 1.0, 10),
                    n_jobs=-1
                )

                train_scores_mean = np.mean(train_scores, axis=1)
                test_scores_mean = np.mean(test_scores, axis=1)

                fig, ax = plt.subplots(figsize=(8, 5))
                ax.plot(train_sizes, train_scores_mean, "o-", color="blue", label="Entrenamiento")
                ax.plot(train_sizes, test_scores_mean, "o-", color="green", label="Validaci√≥n")
                ax.set_title("Curva de Aprendizaje (Cross-validation)")
                ax.set_xlabel("Tama√±o del conjunto de entrenamiento")
                ax.set_ylabel("Score (R¬≤)")
                ax.legend()

                buffer = io.BytesIO()
                plt.savefig(buffer, format="png", bbox_inches="tight")
                buffer.seek(0)
                learning_curve_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                plt.close(fig)

                #importancia de variables
                importances = modelo.feature_importances_
                features = columnas_predictoras
                indices = np.argsort(importances)[::-1]

                fig, ax = plt.subplots(figsize=(8, 6))
                sns.barplot(x=importances[indices], y=np.array(features)[indices], palette="viridis", ax=ax)

                ax.set_title("Importancia de las caracter√≠sticas")
                ax.set_xlabel("Importancia")
                ax.set_ylabel("Caracter√≠sticas")

                buffer = io.BytesIO()
                plt.savefig(buffer, format="png", bbox_inches="tight")
                buffer.seek(0)
                feature_importances_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                plt.close(fig)
            

            except Exception as e:
                print("Error al generar learning curve:", e)

            # Cross-validation (5 particiones por defecto)
            cv_scores = cross_val_score(modelo, X, y, cv=5, scoring="r2" if not es_clasificacion else "accuracy")
            cv_mean = np.mean(cv_scores)
            cv_std = np.std(cv_scores)

            # Calcular m√©tricas
            y_pred = modelo.predict(X_test)
            

            # Crear gr√°fico scatter solo si es regresi√≥n
            if not es_clasificacion:
                try:
                    fig, ax = plt.subplots(figsize=(12, 6))

                    # Eje X como √≠ndice temporal
                    x_axis = range(len(y_test))

                    # Puntos de valores reales
                    ax.scatter(x_axis, y_test.values, label="Datos reales", color="blue", alpha=0.6, s=30)

                    # Puntos de predicci√≥n
                    ax.scatter(x_axis, y_pred, label="Predicci√≥n", color="green", alpha=0.6, s=30)

                    ax.set_xlabel("Tiempo (√≠ndice de muestra)")
                    ax.set_ylabel(columna_objetivo)
                    ax.set_title(f"Comparaci√≥n de valores reales vs predichos ({columna_objetivo})")
                    ax.legend()

                    # Guardar como imagen base64
                    buf = io.BytesIO()
                    plt.tight_layout()
                    plt.savefig(buf, format="png")
                    plt.close(fig)
                    buf.seek(0)
                    scatter_img = base64.b64encode(buf.getvalue()).decode("utf-8")

                    # Generar gr√°fico displot (real vs predicho)
                    fig, ax = plt.subplots(figsize=(8, 5))
                    sns.histplot(y_test, color="blue", kde=True, label="Real", stat="density", ax=ax, alpha=0.4)
                    sns.histplot(y_pred, color="green", kde=True, label="Predicho", stat="density", ax=ax, alpha=0.4)
                    ax.set_title("Distribuci√≥n Real vs Predicho")
                    ax.set_xlabel("Valores")
                    ax.set_ylabel("Densidad")
                    ax.legend()

                    # Convertir a base64
                    buffer = io.BytesIO()
                    plt.savefig(buffer, format="png", bbox_inches="tight")
                    buffer.seek(0)
                    displot_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                    plt.close(fig)

                    # Gr√°fico de correlaci√≥n cruzada (50% de los datos)
                    df_comparacion = pd.DataFrame({
                        "√çndice": range(len(y_test)),
                        "y_real": y_test,
                        "y_pred": y_pred
                    })

                    # Tomar el 50% aleatorio
                    df_sample = df_comparacion.sample(frac=0.5, random_state=42)

                    fig, ax = plt.subplots(figsize=(8, 5))
                    sns.scatterplot(x="√çndice", y="y_real", data=df_sample, ax=ax, color="orange", label="Real")
                    sns.scatterplot(x="√çndice", y="y_pred", data=df_sample, ax=ax, color="blue", label="Predicho")

                    ax.set_title(f"Comparaci√≥n Real vs Predicho ({columna_objetivo}) - Muestra 50%")
                    ax.set_xlabel("√çndice (muestra)")
                    ax.set_ylabel("Valor")
                    ax.legend()

                    buffer = io.BytesIO()
                    fig.savefig(buffer, format="png", bbox_inches="tight")
                    buffer.seek(0)
                    crosscorrelation_img = base64.b64encode(buffer.getvalue()).decode("utf-8")
                    plt.close(fig)
                
                




                except Exception as e:
                    print("Error al generar gr√°fico:", e)

            if es_clasificacion:
                accuracy = accuracy_score(y_test, y_pred)
                metricas = {
                    'accuracy': round(accuracy, 4),
                    'cv_mean': round(cv_mean, 4),
                    'cv_std': round(cv_std, 4),
                    'best_params': best_params,
                    'best_score': round(best_score, 4),
                    'classification_report': classification_report(y_test, y_pred),
                    'n_estimators': modelo.n_estimators,
                    'features_importances': sorted(
                        zip(columnas_predictoras, modelo.feature_importances_),
                        key=lambda x: x[1],
                        reverse=True
                    ),
                    'tipo': 'clasificaci√≥n',
                    'test_size': parametros['test_size'],
                    'test_size_percent': test_size_percent,
                    'random_state_split': parametros['random_state_split'],
                    'random_state_model': parametros['random_state_model'],
                    'max_depth': parametros['max_depth'],
                    'min_samples_split': parametros['min_samples_split'],
                    'min_samples_leaf': parametros['min_samples_leaf']
                }
            else:
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                metricas = {
                    'mae': round(mae, 4),
                    'r2': round(r2, 4),
                    'best_params': best_params,
                    'best_score': round(best_score, 4),
                    'cv_mean': round(cv_mean, 4),
                    'cv_std': round(cv_std, 4),
                    'n_estimators': modelo.n_estimators,
                    'features_importances': sorted(
                        zip(columnas_predictoras, modelo.feature_importances_),
                        key=lambda x: x[1],
                        reverse=True
                    ),
                    'tipo': 'regresi√≥n',
                    'test_size': parametros['test_size'],
                    'test_size_percent': test_size_percent,
                    'random_state_split': parametros['random_state_split'],
                    'random_state_model': parametros['random_state_model'],
                    'max_depth': parametros['max_depth'],
                    'min_samples_split': parametros['min_samples_split'],
                    'min_samples_leaf': parametros['min_samples_leaf']
                }
            
            modelo_info = f"Modelo RandomForest entrenado para predecir '{columna_objetivo}' usando {len(columnas_predictoras)} predictores."
            
            # Hacer predicci√≥n si se proporcionan valores
            if valor_str:
                try:
                    nuevo_valor = [float(v.strip()) for v in valor_str.split(",")]
                    if len(nuevo_valor) != len(columnas_predictoras):
                        messages.error(
                            request,
                            f"Debes ingresar {len(columnas_predictoras)} valores separados por coma (uno por cada predictor)."
                        )
                    else:
                        prediccion = modelo.predict([nuevo_valor])[0]
                        messages.success(
                            request,
                            f"Predicci√≥n para '{columna_objetivo}': {prediccion:.4f}"
                        )
                except ValueError:
                    messages.error(request, "Los valores de entrada deben ser n√∫meros separados por comas.")
            
            # Predecir columna completa
            if predecir_columna:
                predicciones = modelo.predict(X)
                df_predicciones = df.loc[X.index].copy()
                df_predicciones[f'Predicci√≥n_{columna_objetivo}'] = predicciones
                df_predicciones['Error'] = np.abs(y.values - predicciones) if not es_clasificacion else (y.values != predicciones).astype(int)
                messages.success(request, f"Se han generado predicciones para {len(df_predicciones)} filas.")
            
            # Predicci√≥n parcial de datos
            if predecir_parcial:
                n_filas = len(X)
                n_entrenamiento = int(n_filas * (porcentaje_datos / 100))
                indices = X.index.tolist()
                random.shuffle(indices)
                indices_con_target = indices[:n_entrenamiento]
                indices_sin_target = indices[n_entrenamiento:]
                
                if not indices_sin_target:
                    messages.warning(request, "No hay datos para predecir con el porcentaje seleccionado.")
                else:
                    # Entrenar modelo solo con datos conocidos
                    X_conocido = X.loc[indices_con_target]
                    y_conocido = y.loc[indices_con_target]
                    
                    if es_clasificacion:
                        modelo_parcial = RandomForestClassifier(
                            n_estimators=parametros['n_estimators'],
                            random_state=parametros['random_state_model'],
                            max_depth=parametros['max_depth'],
                            min_samples_split=parametros['min_samples_split'],
                            min_samples_leaf=parametros['min_samples_leaf']
                        )
                    else:
                        modelo_parcial = RandomForestRegressor(
                            n_estimators=parametros['n_estimators'],
                            random_state=parametros['random_state_model'],
                            max_depth=parametros['max_depth'],
                            min_samples_split=parametros['min_samples_split'],
                            min_samples_leaf=parametros['min_samples_leaf']
                        )
                    
                    modelo_parcial.fit(X_conocido, y_conocido)
                    predicciones_todas = modelo_parcial.predict(X)
                    
                    df_parcial_predicciones = df.loc[X.index].copy()
                    df_parcial_predicciones[f'Predicci√≥n_{columna_objetivo}'] = predicciones_todas
                    
                    if es_clasificacion:
                        df_parcial_predicciones['Error'] = (y.values != predicciones_todas).astype(int)
                    else:
                        df_parcial_predicciones['Error'] = np.abs(y.values - predicciones_todas)
                    
                    df_parcial_predicciones['Tipo'] = 'Predicho'
                    df_parcial_predicciones.loc[indices_con_target, 'Tipo'] = 'Conocido (Entrenamiento)'
                    
                    total_filas = len(df_parcial_predicciones)
                    conocidos_filas = len(indices_con_target)
                    predichos_filas = len(indices_sin_target)
                    
                    if conocidos_filas > 0:
                        datos_entrenamiento = df_parcial_predicciones.loc[indices_con_target]
                        if es_clasificacion:
                            correctos = len(datos_entrenamiento[datos_entrenamiento['Error'] == 0])
                            accuracy_parcial = round((correctos / conocidos_filas) * 100, 2)
                        else:
                            error_promedio = round(datos_entrenamiento['Error'].mean(), 4)
                    
                    messages.success(request, f"Predicci√≥n parcial completada. {conocidos_filas} filas para entrenamiento, {predichos_filas} filas predichas.")
                
        except Exception as e:
            messages.error(request, f"Error durante el modelado: {str(e)}")
            import traceback
            traceback.print_exc()

    return render(request, "prueba_modelado_randomforest.html", {
        "archivo": archivo,
        "columnas": columnas_numericas,
        "modelo_info": modelo_info,
        "metricas": metricas,
        "df_predicciones": df_predicciones,
        "df_parcial_predicciones": df_parcial_predicciones,
        "es_clasificacion": es_clasificacion,
        "total_filas": total_filas,
        "conocidos_filas": conocidos_filas,
        "predichos_filas": predichos_filas,
        "error_promedio": error_promedio,
        "accuracy_parcial": accuracy_parcial,
        "parametros": parametros,
        "test_size_percent": test_size_percent,
        "train_size_percent": train_size_percent,
        "scatter_img": scatter_img,
        "displot_img": displot_img,
        "crosscorrelation_img": crosscorrelation_img,
        "learning_curve_img": learning_curve_img,
        "feature_importances_img": feature_importances_img,
    })

# Nuevo modelo para predicciones 
from sklearn.linear_model import LinearRegression

def interfaz_modelado_lineal(request, id):
    archivo = get_object_or_404(ArchivoSubido, id=id)
    modelo_info = None
    metricas = None
    scatter_img = None

    try:
        df = pd.read_csv(archivo.archivo.path, sep=None, engine='python', on_bad_lines='skip')
        df.dropna(inplace=True)

        columnas_numericas = df.select_dtypes(include=['number']).columns.tolist()

    except Exception as e:
        messages.error(request, f"Error al cargar archivo: {e}")
        return render(request, "interfaz_modelado_lineal.html", {
            "archivo": archivo,
            "columnas": [],
            "modelo_info": None,
            "metricas": None,
            "scatter_img": None,
        })

    if request.method == "POST":
        columna_objetivo = request.POST.get("columna_objetivo")
        columnas_predictoras = request.POST.getlist("columnas_predictoras")

        if not columna_objetivo or columna_objetivo not in df.columns:
            messages.error(request, "Columna objetivo inv√°lida.")
            return render(request, "interfaz_modelado_lineal.html", {
                "archivo": archivo,
                "columnas": columnas_numericas,
                "modelo_info": None,
                "metricas": None,
                "scatter_img": None,
            })

        X = df[columnas_predictoras].apply(pd.to_numeric, errors="coerce").dropna()
        y = df[columna_objetivo].apply(pd.to_numeric, errors="coerce").dropna()

        X, y = X.align(y, join="inner", axis=0)

        modelo = LinearRegression()
        modelo.fit(X, y)
        y_pred = modelo.predict(X)

        # M√©tricas
        mae = mean_absolute_error(y, y_pred)
        r2 = r2_score(y, y_pred)
        metricas = {"mae": round(mae, 4), "r2": round(r2, 4)}

        modelo_info = f"Modelo de Regresi√≥n Lineal entrenado para predecir '{columna_objetivo}'."

        # Gr√°fico comparativo
        try:
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.scatter(y, y_pred, alpha=0.6)
            ax.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')
            ax.set_xlabel("Valores reales")
            ax.set_ylabel("Predicciones")
            ax.set_title("Comparaci√≥n Real vs Predicho")

            buf = io.BytesIO()
            plt.savefig(buf, format="png", bbox_inches="tight")
            buf.seek(0)
            scatter_img = base64.b64encode(buf.getvalue()).decode("utf-8")
            plt.close(fig)
        except Exception as e:
            print("Error gr√°fico:", e)

    return render(request, "interfaz_modelado_lineal.html", {
        "archivo": archivo,
        "columnas": columnas_numericas,
        "modelo_info": modelo_info,
        "metricas": metricas,
        "scatter_img": scatter_img,
    })


def eliminar_archivo(request, archivo_id):
    archivo = get_object_or_404(ArchivoSubido, pk=archivo_id)
    archivo_path = os.path.join(settings.MEDIA_ROOT, archivo.archivo.name)

    if os.path.exists(archivo_path):
        os.remove(archivo_path)

    archivo.delete()
    
    if request.headers.get('x-requested-with') == 'XMLHttpRequest':
        return JsonResponse({'success': True})
    
    messages.success(request, "Archivo borrado exitosamente")
    return redirect('interfaz')

@require_POST
def eliminar_multiple(request):
    ids = request.POST.getlist("archivos")  # lista de IDs seleccionados
    for archivo_id in ids:
        archivo = get_object_or_404(ArchivoSubido, pk=archivo_id)
        archivo_path = os.path.join(settings.MEDIA_ROOT, archivo.archivo.name)

        if os.path.exists(archivo_path):
            os.remove(archivo_path)

        archivo.delete()

    messages.success(request, f"Se eliminaron {len(ids)} archivo(s).")
    return redirect("interfaz")
"""
path('register/', views.register, name='register')
def register(request):
    if request.method == 'POST':
        form = CustomUserCreationForm(request.POST)
        if form.is_valid():
            user = form.save()
            auth_login(request, user)
            return redirect('interfaz')
    else:
        form = CustomUserCreationForm()
    return render(request, 'register.html', {'form': form})"""

"""Nueva parte de SuperUsers"""
def superuser_required(view_func):
    return user_passes_test(lambda u: u.is_superuser)(view_func)


@superuser_required
def panel_admin(request):
    """
    Vista exclusiva para superusuarios:
    - Crear usuarios nuevos
    - Eliminar im√°genes generadas en /media/*.png
    """
    if request.method == "POST":
        action = request.POST.get("action")

        # üîπ Crear usuario
        if action == "crear_usuario":
            username = request.POST.get("username")
            password = request.POST.get("password")
            is_super = request.POST.get("is_superuser") == "on"

            if not username or not password:
                return JsonResponse({"success": False, "message": "Debes ingresar usuario y contrase√±a."})

            if User.objects.filter(username=username).exists():
                return JsonResponse({"success": False, "message": f"El usuario '{username}' ya existe."})

            user = User.objects.create_user(username=username, password=password)
            if is_super:
                user.is_superuser = True
                user.is_staff = True
                user.save()

            return JsonResponse({"success": True, "message": f"Usuario '{username}' creado con √©xito."})

        # üîπ Eliminar im√°genes .png en /media
        elif action == "eliminar_imagenes":
            media_path = settings.MEDIA_ROOT
            eliminados = 0
            for archivo in os.listdir(media_path):
                if archivo.endswith(".png"):
                    try:
                        os.remove(os.path.join(media_path, archivo))
                        eliminados += 1
                    except:
                        pass
            return JsonResponse({"success": True, "message": f"Se eliminaron {eliminados} im√°genes .png generadas."})

    # üöÄ Render normal solo si GET
    return render(request, "panel_admin.html")